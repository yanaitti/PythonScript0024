{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oyNeAXRBjWEe",
    "outputId": "09240e7a-8fff-4eb4-d5ca-a3978b81444c"
   },
   "outputs": [],
   "source": [
    "# !pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AJNSBMBdAmvk",
    "outputId": "85c76b64-3e5f-4bdc-9b6d-1273cb7133af"
   },
   "outputs": [],
   "source": [
    "# !pip install ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "E7jgXWh-Bj1U"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.model_selection import KFold, train_test_split, TimeSeriesSplit\n",
    "\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "\n",
    "import optuna\n",
    "import ta\n",
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "2X0B-dlnC0RN",
    "outputId": "aabe12a6-2086-4b1a-d096-adb32d75b0e0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107.525</td>\n",
       "      <td>107.552</td>\n",
       "      <td>107.470</td>\n",
       "      <td>107.537</td>\n",
       "      <td>2020-04-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107.537</td>\n",
       "      <td>107.555</td>\n",
       "      <td>107.514</td>\n",
       "      <td>107.540</td>\n",
       "      <td>2020-04-01 00:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>107.540</td>\n",
       "      <td>107.563</td>\n",
       "      <td>107.523</td>\n",
       "      <td>107.523</td>\n",
       "      <td>2020-04-01 00:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107.523</td>\n",
       "      <td>107.527</td>\n",
       "      <td>107.509</td>\n",
       "      <td>107.509</td>\n",
       "      <td>2020-04-01 00:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>107.509</td>\n",
       "      <td>107.551</td>\n",
       "      <td>107.480</td>\n",
       "      <td>107.551</td>\n",
       "      <td>2020-04-01 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27262</th>\n",
       "      <td>109.191</td>\n",
       "      <td>109.206</td>\n",
       "      <td>109.185</td>\n",
       "      <td>109.189</td>\n",
       "      <td>2021-05-05 23:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27263</th>\n",
       "      <td>109.186</td>\n",
       "      <td>109.217</td>\n",
       "      <td>109.150</td>\n",
       "      <td>109.187</td>\n",
       "      <td>2021-05-06 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27264</th>\n",
       "      <td>109.188</td>\n",
       "      <td>109.208</td>\n",
       "      <td>109.178</td>\n",
       "      <td>109.202</td>\n",
       "      <td>2021-05-06 00:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27265</th>\n",
       "      <td>109.197</td>\n",
       "      <td>109.203</td>\n",
       "      <td>109.172</td>\n",
       "      <td>109.174</td>\n",
       "      <td>2021-05-06 00:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27266</th>\n",
       "      <td>109.175</td>\n",
       "      <td>109.184</td>\n",
       "      <td>109.173</td>\n",
       "      <td>109.182</td>\n",
       "      <td>2021-05-06 00:45:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27267 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          open     high      low    close            datetime\n",
       "0      107.525  107.552  107.470  107.537 2020-04-01 00:00:00\n",
       "1      107.537  107.555  107.514  107.540 2020-04-01 00:15:00\n",
       "2      107.540  107.563  107.523  107.523 2020-04-01 00:30:00\n",
       "3      107.523  107.527  107.509  107.509 2020-04-01 00:45:00\n",
       "4      107.509  107.551  107.480  107.551 2020-04-01 01:00:00\n",
       "...        ...      ...      ...      ...                 ...\n",
       "27262  109.191  109.206  109.185  109.189 2021-05-05 23:45:00\n",
       "27263  109.186  109.217  109.150  109.187 2021-05-06 00:00:00\n",
       "27264  109.188  109.208  109.178  109.202 2021-05-06 00:15:00\n",
       "27265  109.197  109.203  109.172  109.174 2021-05-06 00:30:00\n",
       "27266  109.175  109.184  109.173  109.182 2021-05-06 00:45:00\n",
       "\n",
       "[27267 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('inputs/USDJPY_M15.csv', sep='\\t', names=('date', 'time', 'open', 'high', 'low', 'close'), usecols=[0, 1, 2, 3, 4, 5], skiprows=1)\n",
    "data['datetime'] = pd.to_datetime(data['date']  + ' ' + data['time'])\n",
    "data.drop(['date', 'time'], axis=1, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "G_MRVcfEDAza",
    "outputId": "eb1172a8-88e5-43be-ccd8-b3f9578985e2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107.525</td>\n",
       "      <td>107.552</td>\n",
       "      <td>107.470</td>\n",
       "      <td>107.537</td>\n",
       "      <td>2020-04-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107.537</td>\n",
       "      <td>107.555</td>\n",
       "      <td>107.514</td>\n",
       "      <td>107.540</td>\n",
       "      <td>2020-04-01 00:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>107.540</td>\n",
       "      <td>107.563</td>\n",
       "      <td>107.523</td>\n",
       "      <td>107.523</td>\n",
       "      <td>2020-04-01 00:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107.523</td>\n",
       "      <td>107.527</td>\n",
       "      <td>107.509</td>\n",
       "      <td>107.509</td>\n",
       "      <td>2020-04-01 00:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>107.509</td>\n",
       "      <td>107.551</td>\n",
       "      <td>107.480</td>\n",
       "      <td>107.551</td>\n",
       "      <td>2020-04-01 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27262</th>\n",
       "      <td>109.191</td>\n",
       "      <td>109.206</td>\n",
       "      <td>109.185</td>\n",
       "      <td>109.189</td>\n",
       "      <td>2021-05-05 23:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27263</th>\n",
       "      <td>109.186</td>\n",
       "      <td>109.217</td>\n",
       "      <td>109.150</td>\n",
       "      <td>109.187</td>\n",
       "      <td>2021-05-06 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27264</th>\n",
       "      <td>109.188</td>\n",
       "      <td>109.208</td>\n",
       "      <td>109.178</td>\n",
       "      <td>109.202</td>\n",
       "      <td>2021-05-06 00:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27265</th>\n",
       "      <td>109.197</td>\n",
       "      <td>109.203</td>\n",
       "      <td>109.172</td>\n",
       "      <td>109.174</td>\n",
       "      <td>2021-05-06 00:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27266</th>\n",
       "      <td>109.175</td>\n",
       "      <td>109.184</td>\n",
       "      <td>109.173</td>\n",
       "      <td>109.182</td>\n",
       "      <td>2021-05-06 00:45:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27267 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          open     high      low    close            datetime\n",
       "0      107.525  107.552  107.470  107.537 2020-04-01 00:00:00\n",
       "1      107.537  107.555  107.514  107.540 2020-04-01 00:15:00\n",
       "2      107.540  107.563  107.523  107.523 2020-04-01 00:30:00\n",
       "3      107.523  107.527  107.509  107.509 2020-04-01 00:45:00\n",
       "4      107.509  107.551  107.480  107.551 2020-04-01 01:00:00\n",
       "...        ...      ...      ...      ...                 ...\n",
       "27262  109.191  109.206  109.185  109.189 2021-05-05 23:45:00\n",
       "27263  109.186  109.217  109.150  109.187 2021-05-06 00:00:00\n",
       "27264  109.188  109.208  109.178  109.202 2021-05-06 00:15:00\n",
       "27265  109.197  109.203  109.172  109.174 2021-05-06 00:30:00\n",
       "27266  109.175  109.184  109.173  109.182 2021-05-06 00:45:00\n",
       "\n",
       "[27267 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = data.copy()\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_Tz5UhtFDDay"
   },
   "outputs": [],
   "source": [
    "# # extract features from date\n",
    "# all_data['day'] = [i.day for i in all_data['datetime']]\n",
    "# all_data['month'] = [i.month for i in all_data['datetime']]\n",
    "# all_data['year'] = [i.year for i in all_data['datetime']]\n",
    "# all_data['day_of_week'] = [i.dayofweek for i in all_data['datetime']]\n",
    "# all_data['day_of_year'] = [i.dayofyear for i in all_data['datetime']]\n",
    "\n",
    "# all_data['hour'] = [i.hour for i in all_data['datetime']]\n",
    "# all_data['minute'] = [i.minute for i in all_data['datetime']]\n",
    "\n",
    "# all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "mrFHBauEDFbi",
    "outputId": "0b9ceb10-150f-4482-d340-c4aaa88758dd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107.525</td>\n",
       "      <td>107.552</td>\n",
       "      <td>107.470</td>\n",
       "      <td>107.537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107.537</td>\n",
       "      <td>107.555</td>\n",
       "      <td>107.514</td>\n",
       "      <td>107.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>107.540</td>\n",
       "      <td>107.563</td>\n",
       "      <td>107.523</td>\n",
       "      <td>107.523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107.523</td>\n",
       "      <td>107.527</td>\n",
       "      <td>107.509</td>\n",
       "      <td>107.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>107.509</td>\n",
       "      <td>107.551</td>\n",
       "      <td>107.480</td>\n",
       "      <td>107.551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27262</th>\n",
       "      <td>109.191</td>\n",
       "      <td>109.206</td>\n",
       "      <td>109.185</td>\n",
       "      <td>109.189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27263</th>\n",
       "      <td>109.186</td>\n",
       "      <td>109.217</td>\n",
       "      <td>109.150</td>\n",
       "      <td>109.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27264</th>\n",
       "      <td>109.188</td>\n",
       "      <td>109.208</td>\n",
       "      <td>109.178</td>\n",
       "      <td>109.202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27265</th>\n",
       "      <td>109.197</td>\n",
       "      <td>109.203</td>\n",
       "      <td>109.172</td>\n",
       "      <td>109.174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27266</th>\n",
       "      <td>109.175</td>\n",
       "      <td>109.184</td>\n",
       "      <td>109.173</td>\n",
       "      <td>109.182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27267 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          open     high      low    close\n",
       "0      107.525  107.552  107.470  107.537\n",
       "1      107.537  107.555  107.514  107.540\n",
       "2      107.540  107.563  107.523  107.523\n",
       "3      107.523  107.527  107.509  107.509\n",
       "4      107.509  107.551  107.480  107.551\n",
       "...        ...      ...      ...      ...\n",
       "27262  109.191  109.206  109.185  109.189\n",
       "27263  109.186  109.217  109.150  109.187\n",
       "27264  109.188  109.208  109.178  109.202\n",
       "27265  109.197  109.203  109.172  109.174\n",
       "27266  109.175  109.184  109.173  109.182\n",
       "\n",
       "[27267 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset = all_data[['open', 'high', 'low', 'close', 'day', 'month', 'year', 'day_of_week', 'day_of_year', 'hour', 'minute']]\n",
    "dataset = all_data[['open', 'high', 'low', 'close']]\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "FmuDq_PZZvZw"
   },
   "outputs": [],
   "source": [
    "def classify_buy(x):\n",
    "    if x > 0.05:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "aNAm3QCahA0B"
   },
   "outputs": [],
   "source": [
    "def classify_sell(x):\n",
    "    if x < -0.05:\n",
    "        return 2\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "id": "QxFdpB4fDIgi",
    "outputId": "be05b3e6-395b-45bd-b3f1-13d695675c33"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>0</td>\n",
       "      <td>108.413</td>\n",
       "      <td>108.443</td>\n",
       "      <td>108.411</td>\n",
       "      <td>108.416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>1</td>\n",
       "      <td>108.416</td>\n",
       "      <td>108.432</td>\n",
       "      <td>108.411</td>\n",
       "      <td>108.420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>2</td>\n",
       "      <td>108.420</td>\n",
       "      <td>108.585</td>\n",
       "      <td>108.418</td>\n",
       "      <td>108.514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>0</td>\n",
       "      <td>108.514</td>\n",
       "      <td>108.514</td>\n",
       "      <td>108.401</td>\n",
       "      <td>108.443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>0</td>\n",
       "      <td>108.443</td>\n",
       "      <td>108.482</td>\n",
       "      <td>108.397</td>\n",
       "      <td>108.441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>1</td>\n",
       "      <td>108.441</td>\n",
       "      <td>108.473</td>\n",
       "      <td>108.419</td>\n",
       "      <td>108.457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>1</td>\n",
       "      <td>108.457</td>\n",
       "      <td>108.608</td>\n",
       "      <td>108.454</td>\n",
       "      <td>108.599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>2</td>\n",
       "      <td>108.600</td>\n",
       "      <td>108.673</td>\n",
       "      <td>108.572</td>\n",
       "      <td>108.672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0</td>\n",
       "      <td>108.671</td>\n",
       "      <td>108.671</td>\n",
       "      <td>108.595</td>\n",
       "      <td>108.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>1</td>\n",
       "      <td>108.629</td>\n",
       "      <td>108.739</td>\n",
       "      <td>108.575</td>\n",
       "      <td>108.712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>1</td>\n",
       "      <td>108.712</td>\n",
       "      <td>108.925</td>\n",
       "      <td>108.669</td>\n",
       "      <td>108.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>0</td>\n",
       "      <td>108.798</td>\n",
       "      <td>108.996</td>\n",
       "      <td>108.790</td>\n",
       "      <td>108.926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>0</td>\n",
       "      <td>108.932</td>\n",
       "      <td>109.087</td>\n",
       "      <td>108.838</td>\n",
       "      <td>108.929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>1</td>\n",
       "      <td>108.929</td>\n",
       "      <td>108.983</td>\n",
       "      <td>108.855</td>\n",
       "      <td>108.937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>0</td>\n",
       "      <td>108.937</td>\n",
       "      <td>109.040</td>\n",
       "      <td>108.899</td>\n",
       "      <td>108.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>2</td>\n",
       "      <td>108.997</td>\n",
       "      <td>109.051</td>\n",
       "      <td>108.892</td>\n",
       "      <td>108.906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>2</td>\n",
       "      <td>108.906</td>\n",
       "      <td>108.925</td>\n",
       "      <td>108.798</td>\n",
       "      <td>108.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>1</td>\n",
       "      <td>108.866</td>\n",
       "      <td>108.881</td>\n",
       "      <td>108.749</td>\n",
       "      <td>108.881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>1</td>\n",
       "      <td>108.881</td>\n",
       "      <td>108.949</td>\n",
       "      <td>108.846</td>\n",
       "      <td>108.911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>2</td>\n",
       "      <td>108.912</td>\n",
       "      <td>109.006</td>\n",
       "      <td>108.903</td>\n",
       "      <td>108.977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y     open     high      low    close\n",
       "290  0  108.413  108.443  108.411  108.416\n",
       "291  1  108.416  108.432  108.411  108.420\n",
       "292  2  108.420  108.585  108.418  108.514\n",
       "293  0  108.514  108.514  108.401  108.443\n",
       "294  0  108.443  108.482  108.397  108.441\n",
       "295  1  108.441  108.473  108.419  108.457\n",
       "296  1  108.457  108.608  108.454  108.599\n",
       "297  2  108.600  108.673  108.572  108.672\n",
       "298  0  108.671  108.671  108.595  108.629\n",
       "299  1  108.629  108.739  108.575  108.712\n",
       "300  1  108.712  108.925  108.669  108.798\n",
       "301  0  108.798  108.996  108.790  108.926\n",
       "302  0  108.932  109.087  108.838  108.929\n",
       "303  1  108.929  108.983  108.855  108.937\n",
       "304  0  108.937  109.040  108.899  108.996\n",
       "305  2  108.997  109.051  108.892  108.906\n",
       "306  2  108.906  108.925  108.798  108.870\n",
       "307  1  108.866  108.881  108.749  108.881\n",
       "308  1  108.881  108.949  108.846  108.911\n",
       "309  2  108.912  109.006  108.903  108.977"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_HC = dataset['high'].shift(-1) - dataset['close']\n",
    "diff_LC = dataset['low'].shift(-1) - dataset['close']\n",
    "dataset['y'] = diff_HC.apply(classify_buy)\n",
    "dataset['y'] += diff_LC.apply(classify_sell)\n",
    "dataset['y'] = dataset['y'].apply(lambda x: 0 if x == 3 else x)\n",
    "dataset[['y', 'open', 'high', 'low', 'close']][290:310]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EVf9JvIGaU7U",
    "outputId": "a092dd60-fbac-4b4f-afe1-6e2915a6210e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    19618\n",
       "2     3879\n",
       "1     3770\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "QcF0zizZDLsa"
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # X = dataset2.drop(['y'], axis=1)\n",
    "    # y = dataset2['y']\n",
    "\n",
    "    _X_train, _X_test, _y_train, _y_test = train_test_split(X_train, y_train, test_size=0.2, shuffle=False)\n",
    "\n",
    "    # folds = KFold(n_splits = 5, shuffle = True)\n",
    "    # folds = TimeSeriesSplit(n_splits = 8)\n",
    "\n",
    "    # params = {'objective': ['reg:squarederror'], 'max_depth': list(range(2, 10)), 'random_state': [0], 'n_estimators': list(range(50, 200, 50)), 'learning_rate': [0.1, 0.01, 0.001]}\n",
    "    # params = {'objective': ['reg:squarederror'], 'random_state': [0], 'learning_rate': [0.1, 0.01, 0.001]}\n",
    "    # params = {'objective': ['reg:squarederror'], 'max_depth': list(range(2, 10)), 'random_state': [0]}\n",
    "    # params = {'objective': ['reg:squarederror'], 'random_state': [0], 'n_estimators': list(range(50, 200, 50))}\n",
    "    # params = {'objective': ['reg:squarederror'], 'max_depth': list(range(2, 10)), 'random_state': [0], 'n_estimators': list(range(50, 200, 50))}\n",
    "#     boosting_list = ['gbtree', 'gblinear']\n",
    "    objective_list_reg = ['reg:linear', 'reg:gamma', 'reg:tweedie']\n",
    "    metric_list = ['rmse']\n",
    "\n",
    "    params = {\n",
    "#         'boosting':trial.suggest_categorical('boosting', boosting_list),\n",
    "#         'tree_method': 'gpu_hist',\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 25),\n",
    "        'reg_alpha':trial.suggest_int('reg_alpha', 0, 5),\n",
    "        'reg_lambda':trial.suggest_int('reg_lambda', 0, 5),\n",
    "        'min_child_weight':trial.suggest_int('min_child_weight', 0, 5),\n",
    "        'gamma':trial.suggest_int('gamma', 0, 5),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-8, 1.0),\n",
    "        'eval_metric':trial.suggest_categorical('eval_metric', metric_list),\n",
    "        'objective':trial.suggest_categorical('objective', objective_list_reg),\n",
    "        'colsample_bytree':trial.suggest_discrete_uniform('colsample_bytree', 0.1, 1, 0.01),\n",
    "        'colsample_bynode':trial.suggest_discrete_uniform('colsample_bynode', 0.1, 1, 0.01),\n",
    "        'colsample_bylevel':trial.suggest_discrete_uniform('colsample_bylevel', 0.1, 1, 0.01),\n",
    "        'subsample':trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.05),\n",
    "        'nthread' : -1\n",
    "        }\n",
    "\n",
    "    # XGBoost\n",
    "    # xgb = XGBRegressor(tree_method='gpu_hist')\n",
    "    # xgb = XGBRegressor()\n",
    "    # xgb = XGBRegressor(**params)\n",
    "    xgb = XGBClassifier(**params)\n",
    "\n",
    "    # reg_cv_xgb = GridSearchCV(xgb, params, cv=folds, return_train_score=True)\n",
    "    # reg_cv_xgb.fit(X_train, y_train)\n",
    "    xgb.fit(_X_train, _y_train)\n",
    "\n",
    "    # print(reg_cv_xgb.best_params_)\n",
    "    # y_pred = reg_cv_xgb.predict(_X_val)\n",
    "    y_pred = xgb.predict(_X_test)\n",
    "\n",
    "    # y_ = np.concatenate([np.array([None for i in range(len(y_train))]) , y_pred])\n",
    "    # y_ = pd.DataFrame(y_, index=X.index)\n",
    "\n",
    "    # plt.figure(figsize=(16,5))\n",
    "    # plt.plot(y, label='original')\n",
    "    # plt.plot(y_, '--', label='predict')\n",
    "    # plt.legend()\n",
    "    # plt.show()\n",
    "\n",
    "    # plt.figure(figsize=(16,5))\n",
    "    # plt.plot(y[-50:], label='original')\n",
    "    # plt.plot(y_[-50:], '--', label='predict')\n",
    "    # plt.legend()\n",
    "    # plt.show()\n",
    "\n",
    "    # return np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    return 1 - accuracy_score(_y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4KWhAmkCKlWM"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "gHkOs8YPact6",
    "outputId": "20987326-851b-4238-8371-e791aa1a8040"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>y</th>\n",
       "      <th>sma5_close</th>\n",
       "      <th>sma20_close</th>\n",
       "      <th>rsi14_rsi</th>\n",
       "      <th>macd_macd</th>\n",
       "      <th>bband_+2a</th>\n",
       "      <th>bband_-2z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>107.684</td>\n",
       "      <td>107.742</td>\n",
       "      <td>107.642</td>\n",
       "      <td>107.702</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000245</td>\n",
       "      <td>0.999025</td>\n",
       "      <td>56.171987</td>\n",
       "      <td>0.055236</td>\n",
       "      <td>1.001992</td>\n",
       "      <td>0.996057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>107.702</td>\n",
       "      <td>107.845</td>\n",
       "      <td>107.659</td>\n",
       "      <td>107.790</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.998294</td>\n",
       "      <td>60.827529</td>\n",
       "      <td>0.060864</td>\n",
       "      <td>1.001360</td>\n",
       "      <td>0.995228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>107.791</td>\n",
       "      <td>107.822</td>\n",
       "      <td>107.758</td>\n",
       "      <td>107.791</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999451</td>\n",
       "      <td>0.998298</td>\n",
       "      <td>60.878384</td>\n",
       "      <td>0.064660</td>\n",
       "      <td>1.001390</td>\n",
       "      <td>0.995205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>107.791</td>\n",
       "      <td>107.830</td>\n",
       "      <td>107.757</td>\n",
       "      <td>107.780</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999716</td>\n",
       "      <td>0.998458</td>\n",
       "      <td>59.956304</td>\n",
       "      <td>0.066019</td>\n",
       "      <td>1.001625</td>\n",
       "      <td>0.995291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>107.780</td>\n",
       "      <td>107.820</td>\n",
       "      <td>107.731</td>\n",
       "      <td>107.732</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000251</td>\n",
       "      <td>0.999054</td>\n",
       "      <td>55.972369</td>\n",
       "      <td>0.062503</td>\n",
       "      <td>1.002129</td>\n",
       "      <td>0.995978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27262</th>\n",
       "      <td>109.191</td>\n",
       "      <td>109.206</td>\n",
       "      <td>109.185</td>\n",
       "      <td>109.189</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000055</td>\n",
       "      <td>1.000550</td>\n",
       "      <td>36.531102</td>\n",
       "      <td>-0.024820</td>\n",
       "      <td>1.001259</td>\n",
       "      <td>0.999840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27263</th>\n",
       "      <td>109.186</td>\n",
       "      <td>109.217</td>\n",
       "      <td>109.150</td>\n",
       "      <td>109.187</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000066</td>\n",
       "      <td>1.000529</td>\n",
       "      <td>36.188153</td>\n",
       "      <td>-0.025589</td>\n",
       "      <td>1.001272</td>\n",
       "      <td>0.999786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27264</th>\n",
       "      <td>109.188</td>\n",
       "      <td>109.208</td>\n",
       "      <td>109.178</td>\n",
       "      <td>109.202</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>1.000352</td>\n",
       "      <td>40.685663</td>\n",
       "      <td>-0.024704</td>\n",
       "      <td>1.001089</td>\n",
       "      <td>0.999614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27265</th>\n",
       "      <td>109.197</td>\n",
       "      <td>109.203</td>\n",
       "      <td>109.172</td>\n",
       "      <td>109.174</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000134</td>\n",
       "      <td>1.000554</td>\n",
       "      <td>35.636521</td>\n",
       "      <td>-0.025962</td>\n",
       "      <td>1.001302</td>\n",
       "      <td>0.999806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27266</th>\n",
       "      <td>109.175</td>\n",
       "      <td>109.184</td>\n",
       "      <td>109.173</td>\n",
       "      <td>109.182</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000044</td>\n",
       "      <td>1.000428</td>\n",
       "      <td>38.003845</td>\n",
       "      <td>-0.026014</td>\n",
       "      <td>1.001155</td>\n",
       "      <td>0.999701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27242 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          open     high      low    close  y  sma5_close  sma20_close  \\\n",
       "25     107.684  107.742  107.642  107.702  1    1.000245     0.999025   \n",
       "26     107.702  107.845  107.659  107.790  0    0.999438     0.998294   \n",
       "27     107.791  107.822  107.758  107.791  0    0.999451     0.998298   \n",
       "28     107.791  107.830  107.757  107.780  0    0.999716     0.998458   \n",
       "29     107.780  107.820  107.731  107.732  0    1.000251     0.999054   \n",
       "...        ...      ...      ...      ... ..         ...          ...   \n",
       "27262  109.191  109.206  109.185  109.189  0    1.000055     1.000550   \n",
       "27263  109.186  109.217  109.150  109.187  0    1.000066     1.000529   \n",
       "27264  109.188  109.208  109.178  109.202  0    0.999940     1.000352   \n",
       "27265  109.197  109.203  109.172  109.174  0    1.000134     1.000554   \n",
       "27266  109.175  109.184  109.173  109.182  0    1.000044     1.000428   \n",
       "\n",
       "       rsi14_rsi  macd_macd  bband_+2a  bband_-2z  \n",
       "25     56.171987   0.055236   1.001992   0.996057  \n",
       "26     60.827529   0.060864   1.001360   0.995228  \n",
       "27     60.878384   0.064660   1.001390   0.995205  \n",
       "28     59.956304   0.066019   1.001625   0.995291  \n",
       "29     55.972369   0.062503   1.002129   0.995978  \n",
       "...          ...        ...        ...        ...  \n",
       "27262  36.531102  -0.024820   1.001259   0.999840  \n",
       "27263  36.188153  -0.025589   1.001272   0.999786  \n",
       "27264  40.685663  -0.024704   1.001089   0.999614  \n",
       "27265  35.636521  -0.025962   1.001302   0.999806  \n",
       "27266  38.003845  -0.026014   1.001155   0.999701  \n",
       "\n",
       "[27242 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2 = dataset.copy()\n",
    "\n",
    "# for i in range(1, 13):\n",
    "#     dataset2['shift%s'%i] = dataset2['close'].shift(i)\n",
    "\n",
    "# sma\n",
    "sma5 = ta.trend.SMAIndicator(dataset['close'], 5)\n",
    "sma20 = ta.trend.SMAIndicator(dataset['close'], 20)\n",
    "dataset2['sma5_close'] = sma5.sma_indicator() / dataset2['close']\n",
    "dataset2['sma20_close'] = sma20.sma_indicator() / dataset2['close']\n",
    "\n",
    "# rsi\n",
    "rsi14 = ta.momentum.RSIIndicator(dataset['close'], 14)\n",
    "dataset2['rsi14_rsi'] = rsi14.rsi()\n",
    "\n",
    "# macd\n",
    "macd = ta.trend.MACD(dataset2['close'])\n",
    "dataset2['macd_macd'] = macd.macd()\n",
    "\n",
    "# bollinger bands\n",
    "bband = ta.volatility.BollingerBands(dataset2['close'])\n",
    "dataset2['bband_+2a'] = bband.bollinger_hband() / dataset2['close']\n",
    "dataset2['bband_-2z'] = bband.bollinger_lband() / dataset2['close']\n",
    "\n",
    "dataset2 = dataset2.dropna()\n",
    "dataset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uwmhw4Vm8gjr",
    "outputId": "ed6b82f2-fdf1-4bf6-b7d4-cecf866c1b41"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X = dataset2.drop(['y', 'close', 'low', 'high', 'open'], axis=1)\n",
    "X = dataset2.drop(['y'], axis=1)\n",
    "y = dataset2['y']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# feature_importance_model = RandomForestRegressor(random_state=0)\n",
    "feature_importance_model = RandomForestClassifier(random_state=0)\n",
    "feature_importance_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "AR_MPgpy9BJl",
    "outputId": "2c982858-329c-4c9d-9ae3-d3dd28f1d1eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0, 'sma5_close'),\n",
       " Text(1, 0, 'bband_-2z'),\n",
       " Text(2, 0, 'bband_+2a'),\n",
       " Text(3, 0, 'sma20_close'),\n",
       " Text(4, 0, 'macd_macd'),\n",
       " Text(5, 0, 'rsi14_rsi'),\n",
       " Text(6, 0, 'open'),\n",
       " Text(7, 0, 'high'),\n",
       " Text(8, 0, 'low'),\n",
       " Text(9, 0, 'close')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = pd.DataFrame({\"feature\":X.columns,\"importances\":feature_importance_model.feature_importances_})\n",
    "f = f.sort_values(by=\"importances\",ascending=False) #並び替え\n",
    "\n",
    "g = sns.barplot(x=\"feature\",y=\"importances\",data=f)\n",
    "g.set_xticklabels(f[\"feature\"],rotation=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ne094pXM7517",
    "outputId": "f39ca787-b53b-4390-acd4-cb93a2ddcae9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-10 22:15:06,969]\u001b[0m A new study created in memory with name: no-name-89f1e533-7724-418a-acd9-f30d51aa6af2\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:15:30,820]\u001b[0m Trial 0 finished with value: 0.27299839412709337 and parameters: {'max_depth': 23, 'reg_alpha': 0, 'reg_lambda': 2, 'min_child_weight': 3, 'gamma': 0, 'learning_rate': 0.224979678572836, 'eval_metric': 'rmse', 'objective': 'reg:tweedie', 'colsample_bytree': 0.32, 'colsample_bynode': 0.35, 'colsample_bylevel': 0.64, 'subsample': 0.9}. Best is trial 0 with value: 0.27299839412709337.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:15:43,376]\u001b[0m Trial 1 finished with value: 0.19775177793071808 and parameters: {'max_depth': 25, 'reg_alpha': 3, 'reg_lambda': 0, 'min_child_weight': 0, 'gamma': 1, 'learning_rate': 0.00013504805124887648, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.6, 'colsample_bynode': 1.0, 'colsample_bylevel': 0.1, 'subsample': 1.0}. Best is trial 1 with value: 0.19775177793071808.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:15:50,480]\u001b[0m Trial 2 finished with value: 0.19775177793071808 and parameters: {'max_depth': 5, 'reg_alpha': 2, 'reg_lambda': 2, 'min_child_weight': 2, 'gamma': 2, 'learning_rate': 0.00046694750292612094, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.69, 'colsample_bynode': 0.94, 'colsample_bylevel': 0.8, 'subsample': 0.8}. Best is trial 1 with value: 0.19775177793071808.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:16:02,038]\u001b[0m Trial 3 finished with value: 0.1972929571002523 and parameters: {'max_depth': 10, 'reg_alpha': 0, 'reg_lambda': 2, 'min_child_weight': 5, 'gamma': 3, 'learning_rate': 0.002382592398894339, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.97, 'colsample_bynode': 0.75, 'colsample_bylevel': 0.2, 'subsample': 0.75}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:16:05,616]\u001b[0m Trial 4 finished with value: 0.19752236751548524 and parameters: {'max_depth': 2, 'reg_alpha': 5, 'reg_lambda': 1, 'min_child_weight': 0, 'gamma': 3, 'learning_rate': 3.641969749646039e-07, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.6, 'colsample_bynode': 0.30000000000000004, 'colsample_bylevel': 0.78, 'subsample': 0.55}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:16:13,408]\u001b[0m Trial 5 finished with value: 0.2356044964441386 and parameters: {'max_depth': 7, 'reg_alpha': 0, 'reg_lambda': 2, 'min_child_weight': 0, 'gamma': 2, 'learning_rate': 0.26539951294253844, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.51, 'colsample_bynode': 0.28, 'colsample_bylevel': 0.79, 'subsample': 0.5}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:16:22,352]\u001b[0m Trial 6 finished with value: 0.19752236751548524 and parameters: {'max_depth': 9, 'reg_alpha': 2, 'reg_lambda': 1, 'min_child_weight': 4, 'gamma': 4, 'learning_rate': 3.1726449179969045e-05, 'eval_metric': 'rmse', 'objective': 'reg:tweedie', 'colsample_bytree': 0.6799999999999999, 'colsample_bynode': 0.19, 'colsample_bylevel': 0.23, 'subsample': 0.7}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:16:39,137]\u001b[0m Trial 7 finished with value: 0.20004588208304652 and parameters: {'max_depth': 17, 'reg_alpha': 0, 'reg_lambda': 4, 'min_child_weight': 1, 'gamma': 5, 'learning_rate': 0.08034181064046766, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.12000000000000001, 'colsample_bynode': 0.76, 'colsample_bylevel': 0.5700000000000001, 'subsample': 0.65}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:16:43,824]\u001b[0m Trial 8 finished with value: 0.19844000917641658 and parameters: {'max_depth': 3, 'reg_alpha': 3, 'reg_lambda': 1, 'min_child_weight': 4, 'gamma': 1, 'learning_rate': 0.07882316402643022, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.73, 'colsample_bynode': 0.28, 'colsample_bylevel': 0.84, 'subsample': 0.8500000000000001}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-10 22:16:53,263]\u001b[0m Trial 9 finished with value: 0.19752236751548524 and parameters: {'max_depth': 23, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 2, 'learning_rate': 1.0521414011094242e-08, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.21000000000000002, 'colsample_bynode': 0.41000000000000003, 'colsample_bylevel': 0.30000000000000004, 'subsample': 1.0}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:17:00,991]\u001b[0m Trial 10 finished with value: 0.19752236751548524 and parameters: {'max_depth': 13, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 5, 'gamma': 5, 'learning_rate': 0.0022261036161192868, 'eval_metric': 'rmse', 'objective': 'reg:tweedie', 'colsample_bytree': 1.0, 'colsample_bynode': 0.65, 'colsample_bylevel': 0.38, 'subsample': 0.6}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:17:10,105]\u001b[0m Trial 11 finished with value: 0.19752236751548524 and parameters: {'max_depth': 11, 'reg_alpha': 5, 'reg_lambda': 0, 'min_child_weight': 5, 'gamma': 4, 'learning_rate': 4.045599934807369e-07, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.92, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.99, 'subsample': 0.5}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:17:21,263]\u001b[0m Trial 12 finished with value: 0.19752236751548524 and parameters: {'max_depth': 18, 'reg_alpha': 4, 'reg_lambda': 1, 'min_child_weight': 3, 'gamma': 3, 'learning_rate': 1.7138753897082536e-06, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.86, 'colsample_bynode': 0.82, 'colsample_bylevel': 0.43000000000000005, 'subsample': 0.75}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:17:24,941]\u001b[0m Trial 13 finished with value: 0.19752236751548524 and parameters: {'max_depth': 2, 'reg_alpha': 1, 'reg_lambda': 3, 'min_child_weight': 2, 'gamma': 3, 'learning_rate': 1.1397802225759788e-08, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.48, 'colsample_bynode': 0.11, 'colsample_bylevel': 0.6799999999999999, 'subsample': 0.6}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:17:31,935]\u001b[0m Trial 14 finished with value: 0.19752236751548524 and parameters: {'max_depth': 6, 'reg_alpha': 4, 'reg_lambda': 1, 'min_child_weight': 1, 'gamma': 4, 'learning_rate': 0.006009551068126545, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.39, 'colsample_bynode': 0.62, 'colsample_bylevel': 0.99, 'subsample': 0.75}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:17:44,366]\u001b[0m Trial 15 finished with value: 0.1979811883459509 and parameters: {'max_depth': 18, 'reg_alpha': 1, 'reg_lambda': 0, 'min_child_weight': 4, 'gamma': 3, 'learning_rate': 4.297878128625106e-06, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.82, 'colsample_bynode': 0.79, 'colsample_bylevel': 0.11, 'subsample': 0.55}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:17:55,785]\u001b[0m Trial 16 finished with value: 0.19752236751548524 and parameters: {'max_depth': 14, 'reg_alpha': 4, 'reg_lambda': 3, 'min_child_weight': 5, 'gamma': 4, 'learning_rate': 1.9167806644868654e-07, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.94, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.49, 'subsample': 0.9}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:18:08,012]\u001b[0m Trial 17 finished with value: 0.19775177793071808 and parameters: {'max_depth': 15, 'reg_alpha': 4, 'reg_lambda': 4, 'min_child_weight': 5, 'gamma': 4, 'learning_rate': 0.004600075462022283, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.98, 'colsample_bynode': 0.51, 'colsample_bylevel': 0.45999999999999996, 'subsample': 0.95}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:18:18,701]\u001b[0m Trial 18 finished with value: 0.19775177793071808 and parameters: {'max_depth': 10, 'reg_alpha': 1, 'reg_lambda': 2, 'min_child_weight': 0, 'gamma': 1, 'learning_rate': 3.1998461048478164e-05, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.35, 'colsample_bynode': 0.67, 'colsample_bylevel': 0.89, 'subsample': 0.7}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:18:27,842]\u001b[0m Trial 19 finished with value: 0.19752236751548524 and parameters: {'max_depth': 21, 'reg_alpha': 2, 'reg_lambda': 4, 'min_child_weight': 1, 'gamma': 2, 'learning_rate': 2.6630491050636234e-08, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.26, 'colsample_bynode': 0.42000000000000004, 'colsample_bylevel': 0.30000000000000004, 'subsample': 1.0}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:18:40,666]\u001b[0m Trial 20 finished with value: 0.19844000917641658 and parameters: {'max_depth': 25, 'reg_alpha': 1, 'reg_lambda': 3, 'min_child_weight': 2, 'gamma': 0, 'learning_rate': 0.01783166765485007, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.1, 'colsample_bynode': 0.89, 'colsample_bylevel': 0.2, 'subsample': 0.8500000000000001}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:18:48,399]\u001b[0m Trial 21 finished with value: 0.19752236751548524 and parameters: {'max_depth': 12, 'reg_alpha': 5, 'reg_lambda': 1, 'min_child_weight': 5, 'gamma': 5, 'learning_rate': 0.000968936990154214, 'eval_metric': 'rmse', 'objective': 'reg:tweedie', 'colsample_bytree': 0.8099999999999999, 'colsample_bynode': 0.66, 'colsample_bylevel': 0.37, 'subsample': 0.6}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:18:57,211]\u001b[0m Trial 22 finished with value: 0.19752236751548524 and parameters: {'max_depth': 20, 'reg_alpha': 3, 'reg_lambda': 5, 'min_child_weight': 4, 'gamma': 5, 'learning_rate': 0.001334187018864558, 'eval_metric': 'rmse', 'objective': 'reg:tweedie', 'colsample_bytree': 0.98, 'colsample_bynode': 0.61, 'colsample_bylevel': 0.31, 'subsample': 0.65}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:19:05,372]\u001b[0m Trial 23 finished with value: 0.19752236751548524 and parameters: {'max_depth': 10, 'reg_alpha': 2, 'reg_lambda': 4, 'min_child_weight': 3, 'gamma': 2, 'learning_rate': 4.136111824155415e-08, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.9, 'colsample_bynode': 0.43000000000000005, 'colsample_bylevel': 0.18, 'subsample': 0.5}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:19:12,868]\u001b[0m Trial 24 finished with value: 0.19752236751548524 and parameters: {'max_depth': 12, 'reg_alpha': 5, 'reg_lambda': 0, 'min_child_weight': 5, 'gamma': 4, 'learning_rate': 0.0003191454564296687, 'eval_metric': 'rmse', 'objective': 'reg:tweedie', 'colsample_bytree': 0.79, 'colsample_bynode': 0.74, 'colsample_bylevel': 0.35, 'subsample': 0.55}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:19:24,200]\u001b[0m Trial 25 finished with value: 0.1979811883459509 and parameters: {'max_depth': 18, 'reg_alpha': 3, 'reg_lambda': 2, 'min_child_weight': 4, 'gamma': 3, 'learning_rate': 1.2357913725769174e-05, 'eval_metric': 'rmse', 'objective': 'reg:tweedie', 'colsample_bytree': 0.85, 'colsample_bynode': 0.82, 'colsample_bylevel': 0.44000000000000006, 'subsample': 0.75}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:19:37,972]\u001b[0m Trial 26 finished with value: 0.19775177793071808 and parameters: {'max_depth': 16, 'reg_alpha': 4, 'reg_lambda': 3, 'min_child_weight': 3, 'gamma': 3, 'learning_rate': 1.2417781906200821e-06, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.91, 'colsample_bynode': 0.88, 'colsample_bylevel': 0.52, 'subsample': 0.8}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:19:44,366]\u001b[0m Trial 27 finished with value: 0.19752236751548524 and parameters: {'max_depth': 5, 'reg_alpha': 1, 'reg_lambda': 3, 'min_child_weight': 2, 'gamma': 4, 'learning_rate': 0.013314020806994092, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.45999999999999996, 'colsample_bynode': 0.5700000000000001, 'colsample_bylevel': 0.66, 'subsample': 0.7}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-10 22:19:53,651]\u001b[0m Trial 28 finished with value: 0.1979811883459509 and parameters: {'max_depth': 8, 'reg_alpha': 0, 'reg_lambda': 0, 'min_child_weight': 2, 'gamma': 3, 'learning_rate': 0.0001913274434855791, 'eval_metric': 'rmse', 'objective': 'reg:tweedie', 'colsample_bytree': 0.76, 'colsample_bynode': 0.16, 'colsample_bylevel': 0.6799999999999999, 'subsample': 0.6}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:20:00,564]\u001b[0m Trial 29 finished with value: 0.20646937370956642 and parameters: {'max_depth': 5, 'reg_alpha': 4, 'reg_lambda': 2, 'min_child_weight': 1, 'gamma': 2, 'learning_rate': 0.923358418024392, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.30000000000000004, 'colsample_bynode': 0.42000000000000004, 'colsample_bylevel': 0.25, 'subsample': 0.9}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:20:08,246]\u001b[0m Trial 30 finished with value: 0.19752236751548524 and parameters: {'max_depth': 7, 'reg_alpha': 5, 'reg_lambda': 1, 'min_child_weight': 3, 'gamma': 4, 'learning_rate': 0.01086656704349063, 'eval_metric': 'rmse', 'objective': 'reg:tweedie', 'colsample_bytree': 0.4, 'colsample_bynode': 0.72, 'colsample_bylevel': 0.16, 'subsample': 0.8}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:20:16,808]\u001b[0m Trial 31 finished with value: 0.19752236751548524 and parameters: {'max_depth': 12, 'reg_alpha': 5, 'reg_lambda': 1, 'min_child_weight': 5, 'gamma': 5, 'learning_rate': 0.0006381957168796699, 'eval_metric': 'rmse', 'objective': 'reg:tweedie', 'colsample_bytree': 0.77, 'colsample_bynode': 0.72, 'colsample_bylevel': 0.36, 'subsample': 0.8}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:20:25,468]\u001b[0m Trial 32 finished with value: 0.19752236751548524 and parameters: {'max_depth': 12, 'reg_alpha': 3, 'reg_lambda': 5, 'min_child_weight': 4, 'gamma': 5, 'learning_rate': 0.0010701430414338693, 'eval_metric': 'rmse', 'objective': 'reg:tweedie', 'colsample_bytree': 1.0, 'colsample_bynode': 0.6, 'colsample_bylevel': 0.35, 'subsample': 0.65}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:20:32,111]\u001b[0m Trial 33 finished with value: 0.19752236751548524 and parameters: {'max_depth': 5, 'reg_alpha': 0, 'reg_lambda': 3, 'min_child_weight': 3, 'gamma': 4, 'learning_rate': 0.013612301212426028, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.45000000000000007, 'colsample_bynode': 0.54, 'colsample_bylevel': 0.58, 'subsample': 0.8500000000000001}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:20:40,443]\u001b[0m Trial 34 finished with value: 0.19752236751548524 and parameters: {'max_depth': 14, 'reg_alpha': 5, 'reg_lambda': 2, 'min_child_weight': 5, 'gamma': 4, 'learning_rate': 0.00012201911183906772, 'eval_metric': 'rmse', 'objective': 'reg:tweedie', 'colsample_bytree': 0.62, 'colsample_bynode': 0.71, 'colsample_bylevel': 0.12000000000000001, 'subsample': 0.8}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:20:52,303]\u001b[0m Trial 35 finished with value: 0.19752236751548524 and parameters: {'max_depth': 22, 'reg_alpha': 2, 'reg_lambda': 4, 'min_child_weight': 1, 'gamma': 2, 'learning_rate': 4.575427240391791e-08, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.55, 'colsample_bynode': 0.39, 'colsample_bylevel': 0.11, 'subsample': 1.0}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:21:01,497]\u001b[0m Trial 36 finished with value: 0.19752236751548524 and parameters: {'max_depth': 21, 'reg_alpha': 2, 'reg_lambda': 4, 'min_child_weight': 1, 'gamma': 2, 'learning_rate': 4.1445728716439147e-08, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.23, 'colsample_bynode': 0.4, 'colsample_bylevel': 0.15000000000000002, 'subsample': 1.0}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:21:08,302]\u001b[0m Trial 37 finished with value: 0.19752236751548524 and parameters: {'max_depth': 9, 'reg_alpha': 5, 'reg_lambda': 0, 'min_child_weight': 5, 'gamma': 1, 'learning_rate': 0.0002571880777929086, 'eval_metric': 'rmse', 'objective': 'reg:tweedie', 'colsample_bytree': 0.65, 'colsample_bynode': 1.0, 'colsample_bylevel': 0.24000000000000002, 'subsample': 0.5}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:21:16,668]\u001b[0m Trial 38 finished with value: 0.19752236751548524 and parameters: {'max_depth': 9, 'reg_alpha': 3, 'reg_lambda': 0, 'min_child_weight': 4, 'gamma': 0, 'learning_rate': 0.0006666785098097341, 'eval_metric': 'rmse', 'objective': 'reg:tweedie', 'colsample_bytree': 0.6799999999999999, 'colsample_bynode': 0.96, 'colsample_bylevel': 0.26, 'subsample': 0.65}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:21:24,517]\u001b[0m Trial 39 finished with value: 0.19752236751548524 and parameters: {'max_depth': 22, 'reg_alpha': 2, 'reg_lambda': 4, 'min_child_weight': 1, 'gamma': 2, 'learning_rate': 5.681559749178356e-08, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.18, 'colsample_bynode': 0.35, 'colsample_bylevel': 0.13, 'subsample': 0.95}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:21:34,810]\u001b[0m Trial 40 finished with value: 0.19752236751548524 and parameters: {'max_depth': 21, 'reg_alpha': 2, 'reg_lambda': 4, 'min_child_weight': 0, 'gamma': 1, 'learning_rate': 4.5175776531813854e-05, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.28, 'colsample_bynode': 0.45999999999999996, 'colsample_bylevel': 0.29000000000000004, 'subsample': 0.95}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:21:42,132]\u001b[0m Trial 41 finished with value: 0.19752236751548524 and parameters: {'max_depth': 7, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 4, 'gamma': 5, 'learning_rate': 3.916883930967305e-05, 'eval_metric': 'rmse', 'objective': 'reg:tweedie', 'colsample_bytree': 0.4, 'colsample_bynode': 0.7, 'colsample_bylevel': 0.18, 'subsample': 0.8}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:21:47,748]\u001b[0m Trial 42 finished with value: 0.19844000917641658 and parameters: {'max_depth': 4, 'reg_alpha': 0, 'reg_lambda': 5, 'min_child_weight': 4, 'gamma': 5, 'learning_rate': 0.04111394012232048, 'eval_metric': 'rmse', 'objective': 'reg:tweedie', 'colsample_bytree': 0.55, 'colsample_bynode': 0.58, 'colsample_bylevel': 0.59, 'subsample': 0.8}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:22:02,240]\u001b[0m Trial 43 finished with value: 0.1979811883459509 and parameters: {'max_depth': 12, 'reg_alpha': 0, 'reg_lambda': 1, 'min_child_weight': 5, 'gamma': 5, 'learning_rate': 0.001393933557328791, 'eval_metric': 'rmse', 'objective': 'reg:tweedie', 'colsample_bytree': 0.71, 'colsample_bynode': 0.66, 'colsample_bylevel': 0.39, 'subsample': 0.8500000000000001}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:22:13,439]\u001b[0m Trial 44 finished with value: 0.19775177793071808 and parameters: {'max_depth': 14, 'reg_alpha': 5, 'reg_lambda': 2, 'min_child_weight': 3, 'gamma': 4, 'learning_rate': 0.004082103390533144, 'eval_metric': 'rmse', 'objective': 'reg:tweedie', 'colsample_bytree': 0.62, 'colsample_bynode': 0.69, 'colsample_bylevel': 0.6, 'subsample': 0.8500000000000001}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:22:21,952]\u001b[0m Trial 45 finished with value: 0.19752236751548524 and parameters: {'max_depth': 11, 'reg_alpha': 3, 'reg_lambda': 5, 'min_child_weight': 5, 'gamma': 5, 'learning_rate': 0.0003259855162794039, 'eval_metric': 'rmse', 'objective': 'reg:tweedie', 'colsample_bytree': 0.77, 'colsample_bynode': 0.77, 'colsample_bylevel': 0.33, 'subsample': 0.7}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:22:32,689]\u001b[0m Trial 46 finished with value: 0.2388162422573985 and parameters: {'max_depth': 10, 'reg_alpha': 0, 'reg_lambda': 3, 'min_child_weight': 2, 'gamma': 3, 'learning_rate': 0.30512749768891095, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.95, 'colsample_bynode': 0.5700000000000001, 'colsample_bylevel': 0.66, 'subsample': 0.55}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-10 22:22:45,390]\u001b[0m Trial 47 finished with value: 0.1972929571002523 and parameters: {'max_depth': 10, 'reg_alpha': 1, 'reg_lambda': 4, 'min_child_weight': 2, 'gamma': 4, 'learning_rate': 0.00031838706069436013, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.89, 'colsample_bynode': 0.76, 'colsample_bylevel': 0.74, 'subsample': 0.7}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:22:53,819]\u001b[0m Trial 48 finished with value: 0.19752236751548524 and parameters: {'max_depth': 7, 'reg_alpha': 1, 'reg_lambda': 2, 'min_child_weight': 2, 'gamma': 4, 'learning_rate': 0.014723630810262558, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.5, 'colsample_bynode': 0.74, 'colsample_bylevel': 0.73, 'subsample': 0.7}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:23:04,451]\u001b[0m Trial 49 finished with value: 0.19775177793071808 and parameters: {'max_depth': 10, 'reg_alpha': 1, 'reg_lambda': 4, 'min_child_weight': 2, 'gamma': 3, 'learning_rate': 7.449015314365344e-05, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.89, 'colsample_bynode': 0.86, 'colsample_bylevel': 0.74, 'subsample': 0.5}. Best is trial 3 with value: 0.1972929571002523.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:23:19,560]\u001b[0m Trial 50 finished with value: 0.19706354668501946 and parameters: {'max_depth': 13, 'reg_alpha': 0, 'reg_lambda': 5, 'min_child_weight': 3, 'gamma': 4, 'learning_rate': 0.002948253536220635, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.99, 'colsample_bynode': 0.53, 'colsample_bylevel': 0.88, 'subsample': 0.65}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:23:34,116]\u001b[0m Trial 51 finished with value: 0.1979811883459509 and parameters: {'max_depth': 13, 'reg_alpha': 0, 'reg_lambda': 5, 'min_child_weight': 3, 'gamma': 3, 'learning_rate': 0.002858028053448029, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.97, 'colsample_bynode': 0.62, 'colsample_bylevel': 0.92, 'subsample': 0.55}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:23:42,056]\u001b[0m Trial 52 finished with value: 0.19752236751548524 and parameters: {'max_depth': 8, 'reg_alpha': 1, 'reg_lambda': 5, 'min_child_weight': 4, 'gamma': 5, 'learning_rate': 5.615802924940762e-05, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.33, 'colsample_bynode': 0.47, 'colsample_bylevel': 0.87, 'subsample': 0.65}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:23:55,474]\u001b[0m Trial 53 finished with value: 0.19752236751548524 and parameters: {'max_depth': 15, 'reg_alpha': 1, 'reg_lambda': 5, 'min_child_weight': 4, 'gamma': 5, 'learning_rate': 1.54309934191762e-05, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.84, 'colsample_bynode': 0.64, 'colsample_bylevel': 0.84, 'subsample': 0.65}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:24:09,695]\u001b[0m Trial 54 finished with value: 0.19752236751548524 and parameters: {'max_depth': 16, 'reg_alpha': 0, 'reg_lambda': 5, 'min_child_weight': 4, 'gamma': 5, 'learning_rate': 1.7436239473781192e-05, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.85, 'colsample_bynode': 0.62, 'colsample_bylevel': 0.94, 'subsample': 0.6}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:24:14,231]\u001b[0m Trial 55 finished with value: 0.19752236751548524 and parameters: {'max_depth': 3, 'reg_alpha': 1, 'reg_lambda': 4, 'min_child_weight': 3, 'gamma': 4, 'learning_rate': 0.0077223987891924285, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.38, 'colsample_bynode': 0.8099999999999999, 'colsample_bylevel': 0.82, 'subsample': 0.7}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:24:21,352]\u001b[0m Trial 56 finished with value: 0.20004588208304652 and parameters: {'max_depth': 6, 'reg_alpha': 0, 'reg_lambda': 3, 'min_child_weight': 2, 'gamma': 4, 'learning_rate': 0.06571563536672335, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.43000000000000005, 'colsample_bynode': 0.54, 'colsample_bylevel': 0.93, 'subsample': 0.75}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:24:25,062]\u001b[0m Trial 57 finished with value: 0.19752236751548524 and parameters: {'max_depth': 2, 'reg_alpha': 1, 'reg_lambda': 4, 'min_child_weight': 2, 'gamma': 4, 'learning_rate': 0.03370079019122415, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.35, 'colsample_bynode': 0.8, 'colsample_bylevel': 0.78, 'subsample': 0.7}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:24:29,758]\u001b[0m Trial 58 finished with value: 0.1979811883459509 and parameters: {'max_depth': 3, 'reg_alpha': 1, 'reg_lambda': 3, 'min_child_weight': 2, 'gamma': 4, 'learning_rate': 0.04466819720626865, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.94, 'colsample_bynode': 0.77, 'colsample_bylevel': 0.76, 'subsample': 0.7}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:24:37,266]\u001b[0m Trial 59 finished with value: 0.2030282174810737 and parameters: {'max_depth': 6, 'reg_alpha': 1, 'reg_lambda': 1, 'min_child_weight': 2, 'gamma': 4, 'learning_rate': 0.18167385092113245, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.45999999999999996, 'colsample_bynode': 0.85, 'colsample_bylevel': 0.7, 'subsample': 0.75}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:24:51,759]\u001b[0m Trial 60 finished with value: 0.19775177793071808 and parameters: {'max_depth': 16, 'reg_alpha': 0, 'reg_lambda': 3, 'min_child_weight': 3, 'gamma': 3, 'learning_rate': 0.008086145027875804, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.5, 'colsample_bynode': 0.52, 'colsample_bylevel': 0.62, 'subsample': 0.6}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:24:59,768]\u001b[0m Trial 61 finished with value: 0.19752236751548524 and parameters: {'max_depth': 11, 'reg_alpha': 3, 'reg_lambda': 5, 'min_child_weight': 5, 'gamma': 5, 'learning_rate': 0.000318527599885083, 'eval_metric': 'rmse', 'objective': 'reg:tweedie', 'colsample_bytree': 0.89, 'colsample_bynode': 0.32, 'colsample_bylevel': 0.21000000000000002, 'subsample': 0.65}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:25:16,493]\u001b[0m Trial 62 finished with value: 0.19821059876118374 and parameters: {'max_depth': 12, 'reg_alpha': 0, 'reg_lambda': 1, 'min_child_weight': 3, 'gamma': 4, 'learning_rate': 0.001875792056626279, 'eval_metric': 'rmse', 'objective': 'reg:tweedie', 'colsample_bytree': 1.0, 'colsample_bynode': 0.73, 'colsample_bylevel': 0.54, 'subsample': 0.8}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:25:36,777]\u001b[0m Trial 63 finished with value: 0.19821059876118374 and parameters: {'max_depth': 15, 'reg_alpha': 0, 'reg_lambda': 1, 'min_child_weight': 3, 'gamma': 4, 'learning_rate': 0.0005813617269580976, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.87, 'colsample_bynode': 0.5700000000000001, 'colsample_bylevel': 0.96, 'subsample': 0.75}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:25:41,259]\u001b[0m Trial 64 finished with value: 0.19752236751548524 and parameters: {'max_depth': 3, 'reg_alpha': 1, 'reg_lambda': 1, 'min_child_weight': 3, 'gamma': 4, 'learning_rate': 0.003138947861481124, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.38, 'colsample_bynode': 0.94, 'colsample_bylevel': 0.82, 'subsample': 0.7}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:25:51,979]\u001b[0m Trial 65 finished with value: 0.19752236751548524 and parameters: {'max_depth': 13, 'reg_alpha': 5, 'reg_lambda': 2, 'min_child_weight': 5, 'gamma': 5, 'learning_rate': 0.00011921805890932624, 'eval_metric': 'rmse', 'objective': 'reg:tweedie', 'colsample_bytree': 0.99, 'colsample_bynode': 0.69, 'colsample_bylevel': 0.48, 'subsample': 0.8500000000000001}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-10 22:26:04,769]\u001b[0m Trial 66 finished with value: 0.1991282404221152 and parameters: {'max_depth': 11, 'reg_alpha': 0, 'reg_lambda': 1, 'min_child_weight': 3, 'gamma': 3, 'learning_rate': 0.0009358384862863198, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.93, 'colsample_bynode': 0.93, 'colsample_bylevel': 0.41000000000000003, 'subsample': 0.65}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:26:14,026]\u001b[0m Trial 67 finished with value: 0.19821059876118374 and parameters: {'max_depth': 8, 'reg_alpha': 1, 'reg_lambda': 3, 'min_child_weight': 2, 'gamma': 4, 'learning_rate': 0.03143777167764508, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.33, 'colsample_bynode': 0.48, 'colsample_bylevel': 0.89, 'subsample': 0.7}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:26:23,300]\u001b[0m Trial 68 finished with value: 0.19752236751548524 and parameters: {'max_depth': 11, 'reg_alpha': 5, 'reg_lambda': 2, 'min_child_weight': 5, 'gamma': 5, 'learning_rate': 0.008605936365596902, 'eval_metric': 'rmse', 'objective': 'reg:tweedie', 'colsample_bytree': 0.88, 'colsample_bynode': 0.27, 'colsample_bylevel': 0.21000000000000002, 'subsample': 0.8}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:26:32,771]\u001b[0m Trial 69 finished with value: 0.19752236751548524 and parameters: {'max_depth': 9, 'reg_alpha': 2, 'reg_lambda': 4, 'min_child_weight': 1, 'gamma': 2, 'learning_rate': 0.001835073076739972, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.5700000000000001, 'colsample_bynode': 0.37, 'colsample_bylevel': 0.1, 'subsample': 0.75}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:26:48,046]\u001b[0m Trial 70 finished with value: 0.1979811883459509 and parameters: {'max_depth': 14, 'reg_alpha': 0, 'reg_lambda': 2, 'min_child_weight': 5, 'gamma': 4, 'learning_rate': 0.0001520310239856383, 'eval_metric': 'rmse', 'objective': 'reg:tweedie', 'colsample_bytree': 0.65, 'colsample_bynode': 0.6, 'colsample_bylevel': 0.52, 'subsample': 0.8500000000000001}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:26:51,778]\u001b[0m Trial 71 finished with value: 0.19752236751548524 and parameters: {'max_depth': 2, 'reg_alpha': 1, 'reg_lambda': 4, 'min_child_weight': 3, 'gamma': 4, 'learning_rate': 0.00526704091473032, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.36, 'colsample_bynode': 0.85, 'colsample_bylevel': 0.8, 'subsample': 0.7}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:26:58,345]\u001b[0m Trial 72 finished with value: 0.19752236751548524 and parameters: {'max_depth': 24, 'reg_alpha': 2, 'reg_lambda': 4, 'min_child_weight': 1, 'gamma': 2, 'learning_rate': 2.831272030668657e-07, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.13, 'colsample_bynode': 0.38, 'colsample_bylevel': 0.13, 'subsample': 1.0}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:27:12,226]\u001b[0m Trial 73 finished with value: 0.19752236751548524 and parameters: {'max_depth': 24, 'reg_alpha': 2, 'reg_lambda': 2, 'min_child_weight': 0, 'gamma': 2, 'learning_rate': 1.1236391601275548e-07, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.54, 'colsample_bynode': 0.52, 'colsample_bylevel': 0.16, 'subsample': 0.95}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:27:21,261]\u001b[0m Trial 74 finished with value: 0.19752236751548524 and parameters: {'max_depth': 19, 'reg_alpha': 2, 'reg_lambda': 4, 'min_child_weight': 1, 'gamma': 2, 'learning_rate': 1.0971354942239551e-06, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.21000000000000002, 'colsample_bynode': 0.44000000000000006, 'colsample_bylevel': 0.13, 'subsample': 1.0}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:27:33,584]\u001b[0m Trial 75 finished with value: 0.19752236751548524 and parameters: {'max_depth': 20, 'reg_alpha': 2, 'reg_lambda': 4, 'min_child_weight': 1, 'gamma': 2, 'learning_rate': 0.0008962809353367994, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.59, 'colsample_bynode': 0.39, 'colsample_bylevel': 0.1, 'subsample': 0.9}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:27:46,915]\u001b[0m Trial 76 finished with value: 0.19752236751548524 and parameters: {'max_depth': 22, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 0, 'gamma': 1, 'learning_rate': 1.8103855482241276e-08, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.62, 'colsample_bynode': 0.99, 'colsample_bylevel': 0.23, 'subsample': 1.0}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:27:56,842]\u001b[0m Trial 77 finished with value: 0.19775177793071808 and parameters: {'max_depth': 9, 'reg_alpha': 3, 'reg_lambda': 4, 'min_child_weight': 1, 'gamma': 0, 'learning_rate': 0.0004781749176530331, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.6799999999999999, 'colsample_bynode': 0.22, 'colsample_bylevel': 0.26, 'subsample': 0.95}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:28:02,371]\u001b[0m Trial 78 finished with value: 0.19775177793071808 and parameters: {'max_depth': 4, 'reg_alpha': 1, 'reg_lambda': 4, 'min_child_weight': 2, 'gamma': 4, 'learning_rate': 0.025543498963911265, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.41000000000000003, 'colsample_bynode': 0.79, 'colsample_bylevel': 0.78, 'subsample': 0.7}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:28:14,344]\u001b[0m Trial 79 finished with value: 0.1979811883459509 and parameters: {'max_depth': 11, 'reg_alpha': 1, 'reg_lambda': 5, 'min_child_weight': 2, 'gamma': 4, 'learning_rate': 0.01309279657035199, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.96, 'colsample_bynode': 0.31, 'colsample_bylevel': 0.71, 'subsample': 0.75}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:28:18,049]\u001b[0m Trial 80 finished with value: 0.19752236751548524 and parameters: {'max_depth': 2, 'reg_alpha': 1, 'reg_lambda': 1, 'min_child_weight': 3, 'gamma': 4, 'learning_rate': 0.003551496027963979, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.36, 'colsample_bynode': 0.89, 'colsample_bylevel': 0.8, 'subsample': 0.7}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:28:34,060]\u001b[0m Trial 81 finished with value: 0.19752236751548524 and parameters: {'max_depth': 22, 'reg_alpha': 2, 'reg_lambda': 0, 'min_child_weight': 0, 'gamma': 1, 'learning_rate': 0.00023260436552225284, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.65, 'colsample_bynode': 0.45999999999999996, 'colsample_bylevel': 0.25, 'subsample': 0.95}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:28:45,286]\u001b[0m Trial 82 finished with value: 0.19821059876118374 and parameters: {'max_depth': 21, 'reg_alpha': 2, 'reg_lambda': 0, 'min_child_weight': 0, 'gamma': 0, 'learning_rate': 5.5575662980717e-06, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.28, 'colsample_bynode': 1.0, 'colsample_bylevel': 0.16, 'subsample': 1.0}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:28:54,037]\u001b[0m Trial 83 finished with value: 0.19752236751548524 and parameters: {'max_depth': 9, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 1, 'gamma': 1, 'learning_rate': 0.0019514506085115248, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.5700000000000001, 'colsample_bynode': 0.35, 'colsample_bylevel': 0.18, 'subsample': 0.75}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:29:02,214]\u001b[0m Trial 84 finished with value: 0.19752236751548524 and parameters: {'max_depth': 23, 'reg_alpha': 4, 'reg_lambda': 0, 'min_child_weight': 4, 'gamma': 2, 'learning_rate': 1.1764426549795831e-07, 'eval_metric': 'rmse', 'objective': 'reg:tweedie', 'colsample_bytree': 0.2, 'colsample_bynode': 0.98, 'colsample_bylevel': 0.28, 'subsample': 0.9}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-10 22:29:08,834]\u001b[0m Trial 85 finished with value: 0.19752236751548524 and parameters: {'max_depth': 25, 'reg_alpha': 4, 'reg_lambda': 0, 'min_child_weight': 4, 'gamma': 1, 'learning_rate': 3.5422512057055885e-07, 'eval_metric': 'rmse', 'objective': 'reg:tweedie', 'colsample_bytree': 0.14, 'colsample_bynode': 0.93, 'colsample_bylevel': 0.27, 'subsample': 0.9}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:29:20,535]\u001b[0m Trial 86 finished with value: 0.1979811883459509 and parameters: {'max_depth': 25, 'reg_alpha': 3, 'reg_lambda': 2, 'min_child_weight': 0, 'gamma': 0, 'learning_rate': 1.3177783547870008e-07, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.54, 'colsample_bynode': 0.96, 'colsample_bylevel': 0.15000000000000002, 'subsample': 0.95}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:29:31,992]\u001b[0m Trial 87 finished with value: 0.1979811883459509 and parameters: {'max_depth': 10, 'reg_alpha': 0, 'reg_lambda': 3, 'min_child_weight': 5, 'gamma': 3, 'learning_rate': 7.917716516638558e-05, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.71, 'colsample_bynode': 0.54, 'colsample_bylevel': 0.23, 'subsample': 0.8}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:29:39,458]\u001b[0m Trial 88 finished with value: 0.19752236751548524 and parameters: {'max_depth': 9, 'reg_alpha': 5, 'reg_lambda': 3, 'min_child_weight': 5, 'gamma': 0, 'learning_rate': 0.00022511820295505124, 'eval_metric': 'rmse', 'objective': 'reg:tweedie', 'colsample_bytree': 0.61, 'colsample_bynode': 0.75, 'colsample_bylevel': 0.32, 'subsample': 0.65}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:29:48,249]\u001b[0m Trial 89 finished with value: 0.19752236751548524 and parameters: {'max_depth': 13, 'reg_alpha': 5, 'reg_lambda': 2, 'min_child_weight': 5, 'gamma': 5, 'learning_rate': 0.0012459192785793595, 'eval_metric': 'rmse', 'objective': 'reg:tweedie', 'colsample_bytree': 0.82, 'colsample_bynode': 0.72, 'colsample_bylevel': 0.33999999999999997, 'subsample': 0.8}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:29:56,859]\u001b[0m Trial 90 finished with value: 0.19752236751548524 and parameters: {'max_depth': 13, 'reg_alpha': 5, 'reg_lambda': 2, 'min_child_weight': 5, 'gamma': 5, 'learning_rate': 0.0013576501874263418, 'eval_metric': 'rmse', 'objective': 'reg:tweedie', 'colsample_bytree': 0.79, 'colsample_bynode': 0.6799999999999999, 'colsample_bylevel': 0.35, 'subsample': 0.8}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:30:12,241]\u001b[0m Trial 91 finished with value: 0.19752236751548524 and parameters: {'max_depth': 16, 'reg_alpha': 1, 'reg_lambda': 5, 'min_child_weight': 4, 'gamma': 5, 'learning_rate': 1.334864273863269e-05, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.83, 'colsample_bynode': 0.63, 'colsample_bylevel': 0.86, 'subsample': 0.65}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:30:21,587]\u001b[0m Trial 92 finished with value: 0.19775177793071808 and parameters: {'max_depth': 8, 'reg_alpha': 1, 'reg_lambda': 5, 'min_child_weight': 4, 'gamma': 5, 'learning_rate': 1.7608586680243172e-05, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.84, 'colsample_bynode': 0.8099999999999999, 'colsample_bylevel': 0.85, 'subsample': 0.6}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:30:35,175]\u001b[0m Trial 93 finished with value: 0.19752236751548524 and parameters: {'max_depth': 17, 'reg_alpha': 1, 'reg_lambda': 5, 'min_child_weight': 4, 'gamma': 5, 'learning_rate': 1.9917433809746964e-05, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.84, 'colsample_bynode': 0.64, 'colsample_bylevel': 0.86, 'subsample': 0.65}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:30:48,176]\u001b[0m Trial 94 finished with value: 0.19752236751548524 and parameters: {'max_depth': 17, 'reg_alpha': 1, 'reg_lambda': 5, 'min_child_weight': 4, 'gamma': 5, 'learning_rate': 4.76064652389414e-06, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.86, 'colsample_bynode': 0.64, 'colsample_bylevel': 0.88, 'subsample': 0.65}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:30:58,163]\u001b[0m Trial 95 finished with value: 0.1979811883459509 and parameters: {'max_depth': 8, 'reg_alpha': 3, 'reg_lambda': 5, 'min_child_weight': 4, 'gamma': 5, 'learning_rate': 5.1582399396093646e-05, 'eval_metric': 'rmse', 'objective': 'reg:tweedie', 'colsample_bytree': 0.99, 'colsample_bynode': 0.77, 'colsample_bylevel': 0.45000000000000007, 'subsample': 0.7}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:31:04,845]\u001b[0m Trial 96 finished with value: 0.19752236751548524 and parameters: {'max_depth': 7, 'reg_alpha': 4, 'reg_lambda': 0, 'min_child_weight': 3, 'gamma': 1, 'learning_rate': 0.00503153539887509, 'eval_metric': 'rmse', 'objective': 'reg:tweedie', 'colsample_bytree': 0.16, 'colsample_bynode': 0.9, 'colsample_bylevel': 0.29000000000000004, 'subsample': 0.9}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:31:10,718]\u001b[0m Trial 97 finished with value: 0.20233998623537508 and parameters: {'max_depth': 3, 'reg_alpha': 0, 'reg_lambda': 2, 'min_child_weight': 2, 'gamma': 4, 'learning_rate': 0.0994863545965228, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.91, 'colsample_bynode': 0.79, 'colsample_bylevel': 0.82, 'subsample': 0.7}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:31:18,656]\u001b[0m Trial 98 finished with value: 0.1979811883459509 and parameters: {'max_depth': 7, 'reg_alpha': 1, 'reg_lambda': 5, 'min_child_weight': 2, 'gamma': 4, 'learning_rate': 0.016340029371835624, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.43000000000000005, 'colsample_bynode': 0.8099999999999999, 'colsample_bylevel': 0.75, 'subsample': 0.6}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-10 22:31:27,465]\u001b[0m Trial 99 finished with value: 0.19752236751548524 and parameters: {'max_depth': 9, 'reg_alpha': 4, 'reg_lambda': 0, 'min_child_weight': 5, 'gamma': 1, 'learning_rate': 0.00038557110390189075, 'eval_metric': 'rmse', 'objective': 'reg:tweedie', 'colsample_bytree': 0.51, 'colsample_bynode': 0.76, 'colsample_bylevel': 0.28, 'subsample': 0.9}. Best is trial 50 with value: 0.19706354668501946.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "X = dataset2.drop(['y'], axis=1)\n",
    "y = dataset2['y']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# folds = KFold(n_splits = 5, shuffle = True)\n",
    "# folds = TimeSeriesSplit(n_splits = 8)\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_fSMBULEZGvY",
    "outputId": "eb6a41a0-6087-4b22-8a67-642146b1a0ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 13, 'reg_alpha': 0, 'reg_lambda': 5, 'min_child_weight': 3, 'gamma': 4, 'learning_rate': 0.002948253536220635, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.99, 'colsample_bynode': 0.53, 'colsample_bylevel': 0.88, 'subsample': 0.65}\n",
      "0.19706354668501946\n",
      "FrozenTrial(number=50, values=[0.19706354668501946], datetime_start=datetime.datetime(2021, 5, 10, 22, 23, 4, 454793), datetime_complete=datetime.datetime(2021, 5, 10, 22, 23, 19, 557929), params={'max_depth': 13, 'reg_alpha': 0, 'reg_lambda': 5, 'min_child_weight': 3, 'gamma': 4, 'learning_rate': 0.002948253536220635, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.99, 'colsample_bynode': 0.53, 'colsample_bylevel': 0.88, 'subsample': 0.65}, distributions={'max_depth': IntUniformDistribution(high=25, low=2, step=1), 'reg_alpha': IntUniformDistribution(high=5, low=0, step=1), 'reg_lambda': IntUniformDistribution(high=5, low=0, step=1), 'min_child_weight': IntUniformDistribution(high=5, low=0, step=1), 'gamma': IntUniformDistribution(high=5, low=0, step=1), 'learning_rate': LogUniformDistribution(high=1.0, low=1e-08), 'eval_metric': CategoricalDistribution(choices=('rmse',)), 'objective': CategoricalDistribution(choices=('reg:linear', 'reg:gamma', 'reg:tweedie')), 'colsample_bytree': DiscreteUniformDistribution(high=1.0, low=0.1, q=0.01), 'colsample_bynode': DiscreteUniformDistribution(high=1.0, low=0.1, q=0.01), 'colsample_bylevel': DiscreteUniformDistribution(high=1.0, low=0.1, q=0.01), 'subsample': DiscreteUniformDistribution(high=1.0, low=0.5, q=0.05)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=50, state=TrialState.COMPLETE, value=None)\n"
     ]
    }
   ],
   "source": [
    "print(study.best_params)\n",
    "print(study.best_value)\n",
    "print(study.best_trial)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "y0cjWCoAZHaK"
   },
   "outputs": [],
   "source": [
    "xgb_ = XGBClassifier(**study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zBGmfA0v32NA",
    "outputId": "7e8571e3-bd06-4d66-f287-3a97fa5169ea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=0.88,\n",
       "              colsample_bynode=0.53, colsample_bytree=0.99, eval_metric='rmse',\n",
       "              gamma=4, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.002948253536220635,\n",
       "              max_delta_step=0, max_depth=13, min_child_weight=3, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=4,\n",
       "              num_parallel_tree=1, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=5, scale_pos_weight=None, subsample=0.65,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22E5Ojxf6XA-",
    "outputId": "de2569e2-83b6-4a1f-88a9-a216d1e93c7e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7072857405028445"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = xgb_.predict(X_val)\n",
    "accuracy_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "FcDmbeXq7GaS",
    "outputId": "a219b75a-4fe2-4e05-e860-3ad7389196b2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>sma5_close</th>\n",
       "      <th>sma20_close</th>\n",
       "      <th>rsi14_rsi</th>\n",
       "      <th>macd_macd</th>\n",
       "      <th>bband_+2a</th>\n",
       "      <th>bband_-2z</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21818</th>\n",
       "      <td>105.627</td>\n",
       "      <td>105.631</td>\n",
       "      <td>105.585</td>\n",
       "      <td>105.604</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999199</td>\n",
       "      <td>72.038982</td>\n",
       "      <td>0.061794</td>\n",
       "      <td>1.000586</td>\n",
       "      <td>0.997813</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21819</th>\n",
       "      <td>105.604</td>\n",
       "      <td>105.605</td>\n",
       "      <td>105.545</td>\n",
       "      <td>105.551</td>\n",
       "      <td>1.000423</td>\n",
       "      <td>0.999787</td>\n",
       "      <td>58.868331</td>\n",
       "      <td>0.056107</td>\n",
       "      <td>1.001016</td>\n",
       "      <td>0.998557</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21820</th>\n",
       "      <td>105.551</td>\n",
       "      <td>105.592</td>\n",
       "      <td>105.551</td>\n",
       "      <td>105.586</td>\n",
       "      <td>1.000078</td>\n",
       "      <td>0.999544</td>\n",
       "      <td>63.600999</td>\n",
       "      <td>0.053804</td>\n",
       "      <td>1.000655</td>\n",
       "      <td>0.998434</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21821</th>\n",
       "      <td>105.586</td>\n",
       "      <td>105.592</td>\n",
       "      <td>105.555</td>\n",
       "      <td>105.559</td>\n",
       "      <td>1.000250</td>\n",
       "      <td>0.999868</td>\n",
       "      <td>58.051853</td>\n",
       "      <td>0.049232</td>\n",
       "      <td>1.000846</td>\n",
       "      <td>0.998890</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21822</th>\n",
       "      <td>105.559</td>\n",
       "      <td>105.584</td>\n",
       "      <td>105.417</td>\n",
       "      <td>105.418</td>\n",
       "      <td>1.001191</td>\n",
       "      <td>1.001204</td>\n",
       "      <td>38.943087</td>\n",
       "      <td>0.033841</td>\n",
       "      <td>1.002190</td>\n",
       "      <td>1.000218</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27262</th>\n",
       "      <td>109.191</td>\n",
       "      <td>109.206</td>\n",
       "      <td>109.185</td>\n",
       "      <td>109.189</td>\n",
       "      <td>1.000055</td>\n",
       "      <td>1.000550</td>\n",
       "      <td>36.531102</td>\n",
       "      <td>-0.024820</td>\n",
       "      <td>1.001259</td>\n",
       "      <td>0.999840</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27263</th>\n",
       "      <td>109.186</td>\n",
       "      <td>109.217</td>\n",
       "      <td>109.150</td>\n",
       "      <td>109.187</td>\n",
       "      <td>1.000066</td>\n",
       "      <td>1.000529</td>\n",
       "      <td>36.188153</td>\n",
       "      <td>-0.025589</td>\n",
       "      <td>1.001272</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27264</th>\n",
       "      <td>109.188</td>\n",
       "      <td>109.208</td>\n",
       "      <td>109.178</td>\n",
       "      <td>109.202</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>1.000352</td>\n",
       "      <td>40.685663</td>\n",
       "      <td>-0.024704</td>\n",
       "      <td>1.001089</td>\n",
       "      <td>0.999614</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27265</th>\n",
       "      <td>109.197</td>\n",
       "      <td>109.203</td>\n",
       "      <td>109.172</td>\n",
       "      <td>109.174</td>\n",
       "      <td>1.000134</td>\n",
       "      <td>1.000554</td>\n",
       "      <td>35.636521</td>\n",
       "      <td>-0.025962</td>\n",
       "      <td>1.001302</td>\n",
       "      <td>0.999806</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27266</th>\n",
       "      <td>109.175</td>\n",
       "      <td>109.184</td>\n",
       "      <td>109.173</td>\n",
       "      <td>109.182</td>\n",
       "      <td>1.000044</td>\n",
       "      <td>1.000428</td>\n",
       "      <td>38.003845</td>\n",
       "      <td>-0.026014</td>\n",
       "      <td>1.001155</td>\n",
       "      <td>0.999701</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5449 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          open     high      low    close  sma5_close  sma20_close  rsi14_rsi  \\\n",
       "21818  105.627  105.631  105.585  105.604    0.999964     0.999199  72.038982   \n",
       "21819  105.604  105.605  105.545  105.551    1.000423     0.999787  58.868331   \n",
       "21820  105.551  105.592  105.551  105.586    1.000078     0.999544  63.600999   \n",
       "21821  105.586  105.592  105.555  105.559    1.000250     0.999868  58.051853   \n",
       "21822  105.559  105.584  105.417  105.418    1.001191     1.001204  38.943087   \n",
       "...        ...      ...      ...      ...         ...          ...        ...   \n",
       "27262  109.191  109.206  109.185  109.189    1.000055     1.000550  36.531102   \n",
       "27263  109.186  109.217  109.150  109.187    1.000066     1.000529  36.188153   \n",
       "27264  109.188  109.208  109.178  109.202    0.999940     1.000352  40.685663   \n",
       "27265  109.197  109.203  109.172  109.174    1.000134     1.000554  35.636521   \n",
       "27266  109.175  109.184  109.173  109.182    1.000044     1.000428  38.003845   \n",
       "\n",
       "       macd_macd  bband_+2a  bband_-2z  y_pred  y  \n",
       "21818   0.061794   1.000586   0.997813       0  2  \n",
       "21819   0.056107   1.001016   0.998557       0  0  \n",
       "21820   0.053804   1.000655   0.998434       0  0  \n",
       "21821   0.049232   1.000846   0.998890       0  2  \n",
       "21822   0.033841   1.002190   1.000218       0  1  \n",
       "...          ...        ...        ...     ... ..  \n",
       "27262  -0.024820   1.001259   0.999840       0  0  \n",
       "27263  -0.025589   1.001272   0.999786       0  0  \n",
       "27264  -0.024704   1.001089   0.999614       0  0  \n",
       "27265  -0.025962   1.001302   0.999806       0  0  \n",
       "27266  -0.026014   1.001155   0.999701       0  0  \n",
       "\n",
       "[5449 rows x 12 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify = X_val.copy()\n",
    "verify['y_pred'] = y_pred\n",
    "verify['y'] = y_val\n",
    "verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "vHSBnWUFAmiT",
    "outputId": "a954975d-4d8a-4599-c26a-d4847a7e3d47"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>sma5_close</th>\n",
       "      <th>sma20_close</th>\n",
       "      <th>rsi14_rsi</th>\n",
       "      <th>macd_macd</th>\n",
       "      <th>bband_+2a</th>\n",
       "      <th>bband_-2z</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21818</th>\n",
       "      <td>105.627</td>\n",
       "      <td>105.631</td>\n",
       "      <td>105.585</td>\n",
       "      <td>105.604</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999199</td>\n",
       "      <td>72.038982</td>\n",
       "      <td>0.061794</td>\n",
       "      <td>1.000586</td>\n",
       "      <td>0.997813</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21821</th>\n",
       "      <td>105.586</td>\n",
       "      <td>105.592</td>\n",
       "      <td>105.555</td>\n",
       "      <td>105.559</td>\n",
       "      <td>1.000250</td>\n",
       "      <td>0.999868</td>\n",
       "      <td>58.051853</td>\n",
       "      <td>0.049232</td>\n",
       "      <td>1.000846</td>\n",
       "      <td>0.998890</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21822</th>\n",
       "      <td>105.559</td>\n",
       "      <td>105.584</td>\n",
       "      <td>105.417</td>\n",
       "      <td>105.418</td>\n",
       "      <td>1.001191</td>\n",
       "      <td>1.001204</td>\n",
       "      <td>38.943087</td>\n",
       "      <td>0.033841</td>\n",
       "      <td>1.002190</td>\n",
       "      <td>1.000218</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21823</th>\n",
       "      <td>105.418</td>\n",
       "      <td>105.478</td>\n",
       "      <td>105.417</td>\n",
       "      <td>105.455</td>\n",
       "      <td>1.000558</td>\n",
       "      <td>1.000839</td>\n",
       "      <td>44.139336</td>\n",
       "      <td>0.024349</td>\n",
       "      <td>1.001863</td>\n",
       "      <td>0.999814</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21827</th>\n",
       "      <td>105.514</td>\n",
       "      <td>105.528</td>\n",
       "      <td>105.483</td>\n",
       "      <td>105.490</td>\n",
       "      <td>1.000042</td>\n",
       "      <td>1.000535</td>\n",
       "      <td>48.268838</td>\n",
       "      <td>0.012023</td>\n",
       "      <td>1.001500</td>\n",
       "      <td>0.999569</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27231</th>\n",
       "      <td>109.321</td>\n",
       "      <td>109.321</td>\n",
       "      <td>109.267</td>\n",
       "      <td>109.280</td>\n",
       "      <td>1.000282</td>\n",
       "      <td>1.000394</td>\n",
       "      <td>43.299872</td>\n",
       "      <td>-0.010788</td>\n",
       "      <td>1.000958</td>\n",
       "      <td>0.999831</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27232</th>\n",
       "      <td>109.280</td>\n",
       "      <td>109.331</td>\n",
       "      <td>109.273</td>\n",
       "      <td>109.306</td>\n",
       "      <td>1.000079</td>\n",
       "      <td>1.000150</td>\n",
       "      <td>47.310761</td>\n",
       "      <td>-0.010678</td>\n",
       "      <td>1.000718</td>\n",
       "      <td>0.999582</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27233</th>\n",
       "      <td>109.307</td>\n",
       "      <td>109.311</td>\n",
       "      <td>109.143</td>\n",
       "      <td>109.194</td>\n",
       "      <td>1.000822</td>\n",
       "      <td>1.001116</td>\n",
       "      <td>35.621274</td>\n",
       "      <td>-0.019405</td>\n",
       "      <td>1.001881</td>\n",
       "      <td>1.000351</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27236</th>\n",
       "      <td>109.273</td>\n",
       "      <td>109.319</td>\n",
       "      <td>109.263</td>\n",
       "      <td>109.309</td>\n",
       "      <td>0.999627</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>50.072135</td>\n",
       "      <td>-0.017314</td>\n",
       "      <td>1.000654</td>\n",
       "      <td>0.999242</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27237</th>\n",
       "      <td>109.311</td>\n",
       "      <td>109.320</td>\n",
       "      <td>109.211</td>\n",
       "      <td>109.217</td>\n",
       "      <td>1.000306</td>\n",
       "      <td>1.000719</td>\n",
       "      <td>41.323476</td>\n",
       "      <td>-0.021879</td>\n",
       "      <td>1.001441</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1595 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          open     high      low    close  sma5_close  sma20_close  rsi14_rsi  \\\n",
       "21818  105.627  105.631  105.585  105.604    0.999964     0.999199  72.038982   \n",
       "21821  105.586  105.592  105.555  105.559    1.000250     0.999868  58.051853   \n",
       "21822  105.559  105.584  105.417  105.418    1.001191     1.001204  38.943087   \n",
       "21823  105.418  105.478  105.417  105.455    1.000558     1.000839  44.139336   \n",
       "21827  105.514  105.528  105.483  105.490    1.000042     1.000535  48.268838   \n",
       "...        ...      ...      ...      ...         ...          ...        ...   \n",
       "27231  109.321  109.321  109.267  109.280    1.000282     1.000394  43.299872   \n",
       "27232  109.280  109.331  109.273  109.306    1.000079     1.000150  47.310761   \n",
       "27233  109.307  109.311  109.143  109.194    1.000822     1.001116  35.621274   \n",
       "27236  109.273  109.319  109.263  109.309    0.999627     0.999948  50.072135   \n",
       "27237  109.311  109.320  109.211  109.217    1.000306     1.000719  41.323476   \n",
       "\n",
       "       macd_macd  bband_+2a  bband_-2z  y_pred  y  \n",
       "21818   0.061794   1.000586   0.997813       0  2  \n",
       "21821   0.049232   1.000846   0.998890       0  2  \n",
       "21822   0.033841   1.002190   1.000218       0  1  \n",
       "21823   0.024349   1.001863   0.999814       0  1  \n",
       "21827   0.012023   1.001500   0.999569       0  1  \n",
       "...          ...        ...        ...     ... ..  \n",
       "27231  -0.010788   1.000958   0.999831       0  1  \n",
       "27232  -0.010678   1.000718   0.999582       0  2  \n",
       "27233  -0.019405   1.001881   1.000351       0  1  \n",
       "27236  -0.017314   1.000654   0.999242       0  2  \n",
       "27237  -0.021879   1.001441   0.999996       0  2  \n",
       "\n",
       "[1595 rows x 12 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify[verify['y_pred'] != verify['y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n__Cj1n2A8XI",
    "outputId": "2b33a51a-de8d-467d-d8d1-16bbbfffea3f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iA06t_p_BbAh",
    "outputId": "c48fbf79-34f3-4288-90d6-d204ee26f66a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3864\n",
       "2     797\n",
       "1     788\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "cCZrI3maBgrY"
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# filename='model_v2.pkl'\n",
    "# pickle.dump(xgb_, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to JSON\n",
    "xgb_.save_model(\"model_v2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "20210509 - optuna",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
