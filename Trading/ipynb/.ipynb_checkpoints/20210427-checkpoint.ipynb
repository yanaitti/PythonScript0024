{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41d6d1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_num = 1 #何足先を予測するか\n",
    "feature_num = 5 #volume, open, high, low, closeの5項目\n",
    "batch_size = 128\n",
    "time_steps = 50 # lstmのtimesteps\n",
    "moving_average_num = 500 # 移動平均を取るCandle数\n",
    "n_epocs = 30 \n",
    "#データをtrain, testに分割するIndex\n",
    "# val_idx_from = 80000\n",
    "# test_idx_from = 100000\n",
    "\n",
    "lstm_hidden_dim = 16\n",
    "target_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b11f4c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2f06ef89e30>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import gc\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2036f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;OPEN&gt;</th>\n",
       "      <th>&lt;HIGH&gt;</th>\n",
       "      <th>&lt;LOW&gt;</th>\n",
       "      <th>&lt;CLOSE&gt;</th>\n",
       "      <th>&lt;TICKVOL&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107.513</td>\n",
       "      <td>107.754</td>\n",
       "      <td>107.502</td>\n",
       "      <td>107.646</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107.646</td>\n",
       "      <td>107.769</td>\n",
       "      <td>107.629</td>\n",
       "      <td>107.717</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>107.717</td>\n",
       "      <td>107.731</td>\n",
       "      <td>107.635</td>\n",
       "      <td>107.640</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107.641</td>\n",
       "      <td>107.646</td>\n",
       "      <td>107.362</td>\n",
       "      <td>107.375</td>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>107.375</td>\n",
       "      <td>107.591</td>\n",
       "      <td>107.361</td>\n",
       "      <td>107.498</td>\n",
       "      <td>1224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28335</th>\n",
       "      <td>107.877</td>\n",
       "      <td>107.895</td>\n",
       "      <td>107.863</td>\n",
       "      <td>107.893</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28336</th>\n",
       "      <td>107.892</td>\n",
       "      <td>107.902</td>\n",
       "      <td>107.886</td>\n",
       "      <td>107.900</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28337</th>\n",
       "      <td>107.903</td>\n",
       "      <td>107.904</td>\n",
       "      <td>107.885</td>\n",
       "      <td>107.887</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28338</th>\n",
       "      <td>107.886</td>\n",
       "      <td>107.908</td>\n",
       "      <td>107.884</td>\n",
       "      <td>107.888</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28339</th>\n",
       "      <td>107.888</td>\n",
       "      <td>107.903</td>\n",
       "      <td>107.868</td>\n",
       "      <td>107.875</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28340 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        <OPEN>   <HIGH>    <LOW>  <CLOSE>  <TICKVOL>\n",
       "0      107.513  107.754  107.502  107.646        428\n",
       "1      107.646  107.769  107.629  107.717        399\n",
       "2      107.717  107.731  107.635  107.640        180\n",
       "3      107.641  107.646  107.362  107.375        357\n",
       "4      107.375  107.591  107.361  107.498       1224\n",
       "...        ...      ...      ...      ...        ...\n",
       "28335  107.877  107.895  107.863  107.893        272\n",
       "28336  107.892  107.902  107.886  107.900        175\n",
       "28337  107.903  107.904  107.885  107.887         84\n",
       "28338  107.886  107.908  107.884  107.888        104\n",
       "28339  107.888  107.903  107.868  107.875        369\n",
       "\n",
       "[28340 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. CSVファイルの読み込み\n",
    "df = pd.read_csv('inputs/USDJPY_M15.csv', usecols=[2, 3, 4, 5, 6], sep='\\t')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a451f287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 教師データの作成\n",
    "future_price = df.iloc[future_num:]['<CLOSE>'].values\n",
    "curr_price = df.iloc[:-future_num]['<CLOSE>'].values\n",
    "y_data_tmp = future_price - curr_price\n",
    "y_data = np.zeros_like(y_data_tmp)\n",
    "y_data[y_data_tmp > 0] = 1\n",
    "y_data = y_data[moving_average_num:]\n",
    "\n",
    "# 3. 価格の正規化\n",
    "cols = df.columns\n",
    "for col in cols:\n",
    "    df['Roll_' + col] = df[col].rolling(window=500, min_periods=500).mean()\n",
    "    df[col] = df[col] / df['Roll_' + col] - 1\n",
    "\n",
    "#最初の500足分は移動平均データがないため除く。後半の144足分は予測データがないため除く\n",
    "X_data = df.iloc[moving_average_num:-future_num][cols].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test)\n",
    "\n",
    "# 4. データの分割、TorchのTensorに変換\n",
    "#学習用データ\n",
    "X_train = torch.tensor(X_data[:val_idx_from], dtype=torch.float, device=device)\n",
    "y_train = torch.tensor(y_data[:val_idx_from], dtype=torch.float, device=device)\n",
    "#評価用データ\n",
    "X_val   = torch.tensor(X_data[val_idx_from:test_idx_from], dtype=torch.float, device=device)\n",
    "y_val   = y_data[val_idx_from:test_idx_from]\n",
    "#テスト用データ\n",
    "X_test  = torch.tensor(X_data[test_idx_from:], dtype=torch.float, device=device)\n",
    "y_test  = y_data[test_idx_from:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae6a1e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, lstm_input_dim, lstm_hidden_dim, target_dim):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.input_dim = lstm_input_dim\n",
    "        self.hidden_dim = lstm_hidden_dim\n",
    "        self.lstm = nn.LSTM(input_size=lstm_input_dim, \n",
    "                            hidden_size=lstm_hidden_dim,\n",
    "                            num_layers=1, #default\n",
    "                            #dropout=0.2,\n",
    "                            batch_first=True\n",
    "                            )\n",
    "        self.dense = nn.Linear(lstm_hidden_dim, target_dim)\n",
    "\n",
    "    def forward(self, X_input):\n",
    "        _, lstm_out = self.lstm(X_input)\n",
    "        # LSTMの最終出力のみを利用する。\n",
    "        linear_out = self.dense(lstm_out[0].view(X_input.size(0), -1))\n",
    "        return torch.sigmoid(linear_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8b0056d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_feature_data(batch_idx, time_steps, X_data, feature_num, device):\n",
    "    feats = torch.zeros((len(batch_idx), time_steps, feature_num), dtype=torch.float, device=device)\n",
    "    for b_i, b_idx in enumerate(batch_idx):\n",
    "        # 過去のN足分をtime stepのデータとして格納する。\n",
    "        b_slc = slice(b_idx + 1 - time_steps ,b_idx + 1)\n",
    "        feats[b_i, :, :] = X_data[b_slc, :]\n",
    "\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d600015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for training\n",
    "model = LSTMClassifier(feature_num, lstm_hidden_dim, target_dim).to(device)\n",
    "loss_function = nn.BCELoss()\n",
    "optimizer= optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5b99cf7",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (5) must match the existing size (10) at non-singleton dimension 1.  Target sizes: [50, 5].  Tensor sizes: [50, 10]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-e96efe37e897>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mbatch_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mperm_idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt_i\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_i\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;31m# 3. LSTM入力用の時系列データの準備\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mfeats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprep_feature_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0my_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m# 4. pytorch LSTMの学習実施\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-30-a6bfc88e2774>\u001b[0m in \u001b[0;36mprep_feature_data\u001b[1;34m(batch_idx, time_steps, X_data, feature_num, device)\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;31m# 過去のN足分をtime stepのデータとして格納する。\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mb_slc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_idx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtime_steps\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mb_idx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mfeats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mb_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mb_slc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfeats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The expanded size of the tensor (5) must match the existing size (10) at non-singleton dimension 1.  Target sizes: [50, 5].  Tensor sizes: [50, 10]"
     ]
    }
   ],
   "source": [
    "train_size = X_train.size(0)\n",
    "best_acc_score = 0\n",
    "for epoch in range(n_epocs):\n",
    "    # 1. まずはtrainデータのindexをランダムに入れ替える。最初のtime_steps分は使わない。\n",
    "    perm_idx = np.random.permutation(np.arange(time_steps, train_size))\n",
    "    # 2. batch size毎にperm_idxの対象のindexを取得\n",
    "    for t_i in range(0, len(perm_idx), batch_size):\n",
    "        batch_idx = perm_idx[t_i:(t_i + batch_size)]\n",
    "        # 3. LSTM入力用の時系列データの準備\n",
    "        feats = prep_feature_data(batch_idx, time_steps, X_train, feature_num, device)\n",
    "        y_target = y_train[batch_idx]\n",
    "        # 4. pytorch LSTMの学習実施\n",
    "        model.zero_grad()\n",
    "        train_scores = model(feats) # batch size x time steps x feature_num\n",
    "        loss = loss_function(train_scores, y_target.view(-1, 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # 5. validationデータの評価\n",
    "    print('EPOCH: ', str(epoch), ' loss :', loss.item())\n",
    "    with torch.no_grad():\n",
    "        feats_val = prep_feature_data(np.arange(time_steps, X_val.size(0)), time_steps, X_val, feature_num, device)\n",
    "        val_scores = model(feats_val)\n",
    "        tmp_scores = val_scores.view(-1).to('cpu').numpy()\n",
    "        bi_scores = np.round(tmp_scores)\n",
    "        acc_score = accuracy_score(y_val[time_steps:], bi_scores)\n",
    "        roc_score = roc_auc_score(y_val[time_steps:], tmp_scores)\n",
    "        print('Val ACC Score :', acc_score, ' ROC AUC Score :', roc_score)\n",
    "\n",
    "    # 6. validationの評価が良ければモデルを保存\n",
    "    if acc_score > best_acc_score:\n",
    "        best_acc_score = acc_score\n",
    "        torch.save(model.state_dict(),'./models/pytorch_v1.mdl')\n",
    "        print('best score updated, Pytorch model was saved!!', )\n",
    "\n",
    "# 7. bestモデルで予測する。\n",
    "model.load_state_dict(torch.load('./models/pytorch_v1.mdl'))\n",
    "with torch.no_grad():\n",
    "    feats_test = prep_feature_data(np.arange(time_steps, X_test.size(0)), time_steps, X_test, feature_num, device)\n",
    "    val_scores = model(feats_test)\n",
    "    tmp_scores = val_scores.view(-1).to('cpu').numpy()\n",
    "    bi_scores = np.round(tmp_scores)\n",
    "    acc_score = accuracy_score(y_test[time_steps:], bi_scores)\n",
    "    roc_score = roc_auc_score(y_test[time_steps:], tmp_scores)\n",
    "    print('Test ACC Score :', acc_score, ' ROC AUC Score :', roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44d2af2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
