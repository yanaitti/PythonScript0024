{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oyNeAXRBjWEe",
    "outputId": "09240e7a-8fff-4eb4-d5ca-a3978b81444c"
   },
   "outputs": [],
   "source": [
    "# !pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AJNSBMBdAmvk",
    "outputId": "85c76b64-3e5f-4bdc-9b6d-1273cb7133af"
   },
   "outputs": [],
   "source": [
    "# !pip install ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mplfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "E7jgXWh-Bj1U"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.model_selection import KFold, train_test_split, TimeSeriesSplit\n",
    "\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "# import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "\n",
    "import optuna\n",
    "import ta\n",
    "import mplfinance as mpf\n",
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "2X0B-dlnC0RN",
    "outputId": "aabe12a6-2086-4b1a-d096-adb32d75b0e0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107.525</td>\n",
       "      <td>107.552</td>\n",
       "      <td>107.470</td>\n",
       "      <td>107.537</td>\n",
       "      <td>2020-04-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107.537</td>\n",
       "      <td>107.555</td>\n",
       "      <td>107.514</td>\n",
       "      <td>107.540</td>\n",
       "      <td>2020-04-01 00:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>107.540</td>\n",
       "      <td>107.563</td>\n",
       "      <td>107.523</td>\n",
       "      <td>107.523</td>\n",
       "      <td>2020-04-01 00:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107.523</td>\n",
       "      <td>107.527</td>\n",
       "      <td>107.509</td>\n",
       "      <td>107.509</td>\n",
       "      <td>2020-04-01 00:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>107.509</td>\n",
       "      <td>107.551</td>\n",
       "      <td>107.480</td>\n",
       "      <td>107.551</td>\n",
       "      <td>2020-04-01 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27602</th>\n",
       "      <td>108.873</td>\n",
       "      <td>108.873</td>\n",
       "      <td>108.837</td>\n",
       "      <td>108.843</td>\n",
       "      <td>2021-05-11 12:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27603</th>\n",
       "      <td>108.841</td>\n",
       "      <td>108.854</td>\n",
       "      <td>108.746</td>\n",
       "      <td>108.767</td>\n",
       "      <td>2021-05-11 13:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27604</th>\n",
       "      <td>108.768</td>\n",
       "      <td>108.774</td>\n",
       "      <td>108.666</td>\n",
       "      <td>108.698</td>\n",
       "      <td>2021-05-11 13:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27605</th>\n",
       "      <td>108.698</td>\n",
       "      <td>108.736</td>\n",
       "      <td>108.693</td>\n",
       "      <td>108.728</td>\n",
       "      <td>2021-05-11 13:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27606</th>\n",
       "      <td>108.728</td>\n",
       "      <td>108.728</td>\n",
       "      <td>108.715</td>\n",
       "      <td>108.721</td>\n",
       "      <td>2021-05-11 13:45:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27607 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          open     high      low    close            datetime\n",
       "0      107.525  107.552  107.470  107.537 2020-04-01 00:00:00\n",
       "1      107.537  107.555  107.514  107.540 2020-04-01 00:15:00\n",
       "2      107.540  107.563  107.523  107.523 2020-04-01 00:30:00\n",
       "3      107.523  107.527  107.509  107.509 2020-04-01 00:45:00\n",
       "4      107.509  107.551  107.480  107.551 2020-04-01 01:00:00\n",
       "...        ...      ...      ...      ...                 ...\n",
       "27602  108.873  108.873  108.837  108.843 2021-05-11 12:45:00\n",
       "27603  108.841  108.854  108.746  108.767 2021-05-11 13:00:00\n",
       "27604  108.768  108.774  108.666  108.698 2021-05-11 13:15:00\n",
       "27605  108.698  108.736  108.693  108.728 2021-05-11 13:30:00\n",
       "27606  108.728  108.728  108.715  108.721 2021-05-11 13:45:00\n",
       "\n",
       "[27607 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('inputs/USDJPY_M15.csv', sep='\\t', names=('date', 'time', 'open', 'high', 'low', 'close'), usecols=[0, 1, 2, 3, 4, 5], skiprows=1)\n",
    "data['datetime'] = pd.to_datetime(data['date']  + ' ' + data['time'])\n",
    "data.drop(['date', 'time'], axis=1, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "G_MRVcfEDAza",
    "outputId": "eb1172a8-88e5-43be-ccd8-b3f9578985e2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107.525</td>\n",
       "      <td>107.552</td>\n",
       "      <td>107.470</td>\n",
       "      <td>107.537</td>\n",
       "      <td>2020-04-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107.537</td>\n",
       "      <td>107.555</td>\n",
       "      <td>107.514</td>\n",
       "      <td>107.540</td>\n",
       "      <td>2020-04-01 00:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>107.540</td>\n",
       "      <td>107.563</td>\n",
       "      <td>107.523</td>\n",
       "      <td>107.523</td>\n",
       "      <td>2020-04-01 00:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107.523</td>\n",
       "      <td>107.527</td>\n",
       "      <td>107.509</td>\n",
       "      <td>107.509</td>\n",
       "      <td>2020-04-01 00:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>107.509</td>\n",
       "      <td>107.551</td>\n",
       "      <td>107.480</td>\n",
       "      <td>107.551</td>\n",
       "      <td>2020-04-01 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27602</th>\n",
       "      <td>108.873</td>\n",
       "      <td>108.873</td>\n",
       "      <td>108.837</td>\n",
       "      <td>108.843</td>\n",
       "      <td>2021-05-11 12:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27603</th>\n",
       "      <td>108.841</td>\n",
       "      <td>108.854</td>\n",
       "      <td>108.746</td>\n",
       "      <td>108.767</td>\n",
       "      <td>2021-05-11 13:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27604</th>\n",
       "      <td>108.768</td>\n",
       "      <td>108.774</td>\n",
       "      <td>108.666</td>\n",
       "      <td>108.698</td>\n",
       "      <td>2021-05-11 13:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27605</th>\n",
       "      <td>108.698</td>\n",
       "      <td>108.736</td>\n",
       "      <td>108.693</td>\n",
       "      <td>108.728</td>\n",
       "      <td>2021-05-11 13:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27606</th>\n",
       "      <td>108.728</td>\n",
       "      <td>108.728</td>\n",
       "      <td>108.715</td>\n",
       "      <td>108.721</td>\n",
       "      <td>2021-05-11 13:45:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27607 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          open     high      low    close            datetime\n",
       "0      107.525  107.552  107.470  107.537 2020-04-01 00:00:00\n",
       "1      107.537  107.555  107.514  107.540 2020-04-01 00:15:00\n",
       "2      107.540  107.563  107.523  107.523 2020-04-01 00:30:00\n",
       "3      107.523  107.527  107.509  107.509 2020-04-01 00:45:00\n",
       "4      107.509  107.551  107.480  107.551 2020-04-01 01:00:00\n",
       "...        ...      ...      ...      ...                 ...\n",
       "27602  108.873  108.873  108.837  108.843 2021-05-11 12:45:00\n",
       "27603  108.841  108.854  108.746  108.767 2021-05-11 13:00:00\n",
       "27604  108.768  108.774  108.666  108.698 2021-05-11 13:15:00\n",
       "27605  108.698  108.736  108.693  108.728 2021-05-11 13:30:00\n",
       "27606  108.728  108.728  108.715  108.721 2021-05-11 13:45:00\n",
       "\n",
       "[27607 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = data.copy()\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_Tz5UhtFDDay"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>datetime</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107.525</td>\n",
       "      <td>107.552</td>\n",
       "      <td>107.470</td>\n",
       "      <td>107.537</td>\n",
       "      <td>2020-04-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107.537</td>\n",
       "      <td>107.555</td>\n",
       "      <td>107.514</td>\n",
       "      <td>107.540</td>\n",
       "      <td>2020-04-01 00:15:00</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>107.540</td>\n",
       "      <td>107.563</td>\n",
       "      <td>107.523</td>\n",
       "      <td>107.523</td>\n",
       "      <td>2020-04-01 00:30:00</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107.523</td>\n",
       "      <td>107.527</td>\n",
       "      <td>107.509</td>\n",
       "      <td>107.509</td>\n",
       "      <td>2020-04-01 00:45:00</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>107.509</td>\n",
       "      <td>107.551</td>\n",
       "      <td>107.480</td>\n",
       "      <td>107.551</td>\n",
       "      <td>2020-04-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27602</th>\n",
       "      <td>108.873</td>\n",
       "      <td>108.873</td>\n",
       "      <td>108.837</td>\n",
       "      <td>108.843</td>\n",
       "      <td>2021-05-11 12:45:00</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>12</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27603</th>\n",
       "      <td>108.841</td>\n",
       "      <td>108.854</td>\n",
       "      <td>108.746</td>\n",
       "      <td>108.767</td>\n",
       "      <td>2021-05-11 13:00:00</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27604</th>\n",
       "      <td>108.768</td>\n",
       "      <td>108.774</td>\n",
       "      <td>108.666</td>\n",
       "      <td>108.698</td>\n",
       "      <td>2021-05-11 13:15:00</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27605</th>\n",
       "      <td>108.698</td>\n",
       "      <td>108.736</td>\n",
       "      <td>108.693</td>\n",
       "      <td>108.728</td>\n",
       "      <td>2021-05-11 13:30:00</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27606</th>\n",
       "      <td>108.728</td>\n",
       "      <td>108.728</td>\n",
       "      <td>108.715</td>\n",
       "      <td>108.721</td>\n",
       "      <td>2021-05-11 13:45:00</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>13</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27607 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          open     high      low    close            datetime  day  month  \\\n",
       "0      107.525  107.552  107.470  107.537 2020-04-01 00:00:00    1      4   \n",
       "1      107.537  107.555  107.514  107.540 2020-04-01 00:15:00    1      4   \n",
       "2      107.540  107.563  107.523  107.523 2020-04-01 00:30:00    1      4   \n",
       "3      107.523  107.527  107.509  107.509 2020-04-01 00:45:00    1      4   \n",
       "4      107.509  107.551  107.480  107.551 2020-04-01 01:00:00    1      4   \n",
       "...        ...      ...      ...      ...                 ...  ...    ...   \n",
       "27602  108.873  108.873  108.837  108.843 2021-05-11 12:45:00   11      5   \n",
       "27603  108.841  108.854  108.746  108.767 2021-05-11 13:00:00   11      5   \n",
       "27604  108.768  108.774  108.666  108.698 2021-05-11 13:15:00   11      5   \n",
       "27605  108.698  108.736  108.693  108.728 2021-05-11 13:30:00   11      5   \n",
       "27606  108.728  108.728  108.715  108.721 2021-05-11 13:45:00   11      5   \n",
       "\n",
       "       year  day_of_week  day_of_year  hour  minute  \n",
       "0      2020            2           92     0       0  \n",
       "1      2020            2           92     0      15  \n",
       "2      2020            2           92     0      30  \n",
       "3      2020            2           92     0      45  \n",
       "4      2020            2           92     1       0  \n",
       "...     ...          ...          ...   ...     ...  \n",
       "27602  2021            1          131    12      45  \n",
       "27603  2021            1          131    13       0  \n",
       "27604  2021            1          131    13      15  \n",
       "27605  2021            1          131    13      30  \n",
       "27606  2021            1          131    13      45  \n",
       "\n",
       "[27607 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract features from date\n",
    "all_data['day'] = [i.day for i in all_data['datetime']]\n",
    "all_data['month'] = [i.month for i in all_data['datetime']]\n",
    "all_data['year'] = [i.year for i in all_data['datetime']]\n",
    "all_data['day_of_week'] = [i.dayofweek for i in all_data['datetime']]\n",
    "all_data['day_of_year'] = [i.dayofyear for i in all_data['datetime']]\n",
    "\n",
    "all_data['hour'] = [i.hour for i in all_data['datetime']]\n",
    "all_data['minute'] = [i.minute for i in all_data['datetime']]\n",
    "\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "mrFHBauEDFbi",
    "outputId": "0b9ceb10-150f-4482-d340-c4aaa88758dd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107.525</td>\n",
       "      <td>107.552</td>\n",
       "      <td>107.470</td>\n",
       "      <td>107.537</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107.537</td>\n",
       "      <td>107.555</td>\n",
       "      <td>107.514</td>\n",
       "      <td>107.540</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>107.540</td>\n",
       "      <td>107.563</td>\n",
       "      <td>107.523</td>\n",
       "      <td>107.523</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107.523</td>\n",
       "      <td>107.527</td>\n",
       "      <td>107.509</td>\n",
       "      <td>107.509</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>107.509</td>\n",
       "      <td>107.551</td>\n",
       "      <td>107.480</td>\n",
       "      <td>107.551</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27602</th>\n",
       "      <td>108.873</td>\n",
       "      <td>108.873</td>\n",
       "      <td>108.837</td>\n",
       "      <td>108.843</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>12</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27603</th>\n",
       "      <td>108.841</td>\n",
       "      <td>108.854</td>\n",
       "      <td>108.746</td>\n",
       "      <td>108.767</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27604</th>\n",
       "      <td>108.768</td>\n",
       "      <td>108.774</td>\n",
       "      <td>108.666</td>\n",
       "      <td>108.698</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27605</th>\n",
       "      <td>108.698</td>\n",
       "      <td>108.736</td>\n",
       "      <td>108.693</td>\n",
       "      <td>108.728</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27606</th>\n",
       "      <td>108.728</td>\n",
       "      <td>108.728</td>\n",
       "      <td>108.715</td>\n",
       "      <td>108.721</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>13</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27607 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          open     high      low    close  day  month  year  day_of_week  \\\n",
       "0      107.525  107.552  107.470  107.537    1      4  2020            2   \n",
       "1      107.537  107.555  107.514  107.540    1      4  2020            2   \n",
       "2      107.540  107.563  107.523  107.523    1      4  2020            2   \n",
       "3      107.523  107.527  107.509  107.509    1      4  2020            2   \n",
       "4      107.509  107.551  107.480  107.551    1      4  2020            2   \n",
       "...        ...      ...      ...      ...  ...    ...   ...          ...   \n",
       "27602  108.873  108.873  108.837  108.843   11      5  2021            1   \n",
       "27603  108.841  108.854  108.746  108.767   11      5  2021            1   \n",
       "27604  108.768  108.774  108.666  108.698   11      5  2021            1   \n",
       "27605  108.698  108.736  108.693  108.728   11      5  2021            1   \n",
       "27606  108.728  108.728  108.715  108.721   11      5  2021            1   \n",
       "\n",
       "       day_of_year  hour  minute  \n",
       "0               92     0       0  \n",
       "1               92     0      15  \n",
       "2               92     0      30  \n",
       "3               92     0      45  \n",
       "4               92     1       0  \n",
       "...            ...   ...     ...  \n",
       "27602          131    12      45  \n",
       "27603          131    13       0  \n",
       "27604          131    13      15  \n",
       "27605          131    13      30  \n",
       "27606          131    13      45  \n",
       "\n",
       "[27607 rows x 11 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = all_data[['open', 'high', 'low', 'close', 'day', 'month', 'year', 'day_of_week', 'day_of_year', 'hour', 'minute']]\n",
    "# dataset = all_data[['open', 'high', 'low', 'close']]\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "FmuDq_PZZvZw"
   },
   "outputs": [],
   "source": [
    "def classify_buy(x):\n",
    "    if x > 0.05:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "aNAm3QCahA0B"
   },
   "outputs": [],
   "source": [
    "def classify_sell(x):\n",
    "    if x < -0.05:\n",
    "        return 2\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "id": "QxFdpB4fDIgi",
    "outputId": "be05b3e6-395b-45bd-b3f1-13d695675c33"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>0</td>\n",
       "      <td>108.413</td>\n",
       "      <td>108.443</td>\n",
       "      <td>108.411</td>\n",
       "      <td>108.416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>1</td>\n",
       "      <td>108.416</td>\n",
       "      <td>108.432</td>\n",
       "      <td>108.411</td>\n",
       "      <td>108.420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>2</td>\n",
       "      <td>108.420</td>\n",
       "      <td>108.585</td>\n",
       "      <td>108.418</td>\n",
       "      <td>108.514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>0</td>\n",
       "      <td>108.514</td>\n",
       "      <td>108.514</td>\n",
       "      <td>108.401</td>\n",
       "      <td>108.443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>0</td>\n",
       "      <td>108.443</td>\n",
       "      <td>108.482</td>\n",
       "      <td>108.397</td>\n",
       "      <td>108.441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>1</td>\n",
       "      <td>108.441</td>\n",
       "      <td>108.473</td>\n",
       "      <td>108.419</td>\n",
       "      <td>108.457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>1</td>\n",
       "      <td>108.457</td>\n",
       "      <td>108.608</td>\n",
       "      <td>108.454</td>\n",
       "      <td>108.599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>2</td>\n",
       "      <td>108.600</td>\n",
       "      <td>108.673</td>\n",
       "      <td>108.572</td>\n",
       "      <td>108.672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0</td>\n",
       "      <td>108.671</td>\n",
       "      <td>108.671</td>\n",
       "      <td>108.595</td>\n",
       "      <td>108.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>1</td>\n",
       "      <td>108.629</td>\n",
       "      <td>108.739</td>\n",
       "      <td>108.575</td>\n",
       "      <td>108.712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>1</td>\n",
       "      <td>108.712</td>\n",
       "      <td>108.925</td>\n",
       "      <td>108.669</td>\n",
       "      <td>108.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>0</td>\n",
       "      <td>108.798</td>\n",
       "      <td>108.996</td>\n",
       "      <td>108.790</td>\n",
       "      <td>108.926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>0</td>\n",
       "      <td>108.932</td>\n",
       "      <td>109.087</td>\n",
       "      <td>108.838</td>\n",
       "      <td>108.929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>1</td>\n",
       "      <td>108.929</td>\n",
       "      <td>108.983</td>\n",
       "      <td>108.855</td>\n",
       "      <td>108.937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>0</td>\n",
       "      <td>108.937</td>\n",
       "      <td>109.040</td>\n",
       "      <td>108.899</td>\n",
       "      <td>108.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>2</td>\n",
       "      <td>108.997</td>\n",
       "      <td>109.051</td>\n",
       "      <td>108.892</td>\n",
       "      <td>108.906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>2</td>\n",
       "      <td>108.906</td>\n",
       "      <td>108.925</td>\n",
       "      <td>108.798</td>\n",
       "      <td>108.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>1</td>\n",
       "      <td>108.866</td>\n",
       "      <td>108.881</td>\n",
       "      <td>108.749</td>\n",
       "      <td>108.881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>1</td>\n",
       "      <td>108.881</td>\n",
       "      <td>108.949</td>\n",
       "      <td>108.846</td>\n",
       "      <td>108.911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>2</td>\n",
       "      <td>108.912</td>\n",
       "      <td>109.006</td>\n",
       "      <td>108.903</td>\n",
       "      <td>108.977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y     open     high      low    close\n",
       "290  0  108.413  108.443  108.411  108.416\n",
       "291  1  108.416  108.432  108.411  108.420\n",
       "292  2  108.420  108.585  108.418  108.514\n",
       "293  0  108.514  108.514  108.401  108.443\n",
       "294  0  108.443  108.482  108.397  108.441\n",
       "295  1  108.441  108.473  108.419  108.457\n",
       "296  1  108.457  108.608  108.454  108.599\n",
       "297  2  108.600  108.673  108.572  108.672\n",
       "298  0  108.671  108.671  108.595  108.629\n",
       "299  1  108.629  108.739  108.575  108.712\n",
       "300  1  108.712  108.925  108.669  108.798\n",
       "301  0  108.798  108.996  108.790  108.926\n",
       "302  0  108.932  109.087  108.838  108.929\n",
       "303  1  108.929  108.983  108.855  108.937\n",
       "304  0  108.937  109.040  108.899  108.996\n",
       "305  2  108.997  109.051  108.892  108.906\n",
       "306  2  108.906  108.925  108.798  108.870\n",
       "307  1  108.866  108.881  108.749  108.881\n",
       "308  1  108.881  108.949  108.846  108.911\n",
       "309  2  108.912  109.006  108.903  108.977"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_HC = dataset['high'].shift(-1) - dataset['close']\n",
    "diff_LC = dataset['low'].shift(-1) - dataset['close']\n",
    "dataset['y'] = diff_HC.apply(classify_buy)\n",
    "dataset['y'] += diff_LC.apply(classify_sell)\n",
    "dataset['y'] = dataset['y'].apply(lambda x: 0 if x == 3 else x)\n",
    "dataset[['y', 'open', 'high', 'low', 'close']][290:310]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EVf9JvIGaU7U",
    "outputId": "a092dd60-fbac-4b4f-afe1-6e2915a6210e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    19861\n",
       "2     3924\n",
       "1     3822\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "QcF0zizZDLsa"
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # X = dataset2.drop(['y'], axis=1)\n",
    "    # y = dataset2['y']\n",
    "\n",
    "    _X_train, _X_test, _y_train, _y_test = train_test_split(X_train, y_train, test_size=0.2, shuffle=False)\n",
    "\n",
    "    # folds = KFold(n_splits = 5, shuffle = True)\n",
    "    # folds = TimeSeriesSplit(n_splits = 8)\n",
    "\n",
    "    # params = {'objective': ['reg:squarederror'], 'max_depth': list(range(2, 10)), 'random_state': [0], 'n_estimators': list(range(50, 200, 50)), 'learning_rate': [0.1, 0.01, 0.001]}\n",
    "    # params = {'objective': ['reg:squarederror'], 'random_state': [0], 'learning_rate': [0.1, 0.01, 0.001]}\n",
    "    # params = {'objective': ['reg:squarederror'], 'max_depth': list(range(2, 10)), 'random_state': [0]}\n",
    "    # params = {'objective': ['reg:squarederror'], 'random_state': [0], 'n_estimators': list(range(50, 200, 50))}\n",
    "    # params = {'objective': ['reg:squarederror'], 'max_depth': list(range(2, 10)), 'random_state': [0], 'n_estimators': list(range(50, 200, 50))}\n",
    "#     boosting_list = ['gbtree', 'gblinear']\n",
    "    objective_list_reg = ['reg:linear', 'reg:gamma', 'reg:tweedie']\n",
    "    metric_list = ['rmse']\n",
    "\n",
    "    params = {\n",
    "#         'boosting':trial.suggest_categorical('boosting', boosting_list),\n",
    "#         'tree_method': 'gpu_hist',\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 25),\n",
    "        'reg_alpha':trial.suggest_int('reg_alpha', 0, 5),\n",
    "        'reg_lambda':trial.suggest_int('reg_lambda', 0, 5),\n",
    "        'min_child_weight':trial.suggest_int('min_child_weight', 0, 5),\n",
    "        'gamma':trial.suggest_int('gamma', 0, 5),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-8, 1.0),\n",
    "        'eval_metric':trial.suggest_categorical('eval_metric', metric_list),\n",
    "        'objective':trial.suggest_categorical('objective', objective_list_reg),\n",
    "        'colsample_bytree':trial.suggest_discrete_uniform('colsample_bytree', 0.1, 1, 0.01),\n",
    "        'colsample_bynode':trial.suggest_discrete_uniform('colsample_bynode', 0.1, 1, 0.01),\n",
    "        'colsample_bylevel':trial.suggest_discrete_uniform('colsample_bylevel', 0.1, 1, 0.01),\n",
    "        'subsample':trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.05),\n",
    "        'nthread' : -1\n",
    "        }\n",
    "\n",
    "    # XGBoost\n",
    "    # xgb = XGBRegressor(tree_method='gpu_hist')\n",
    "    # xgb = XGBRegressor()\n",
    "    # xgb = XGBRegressor(**params)\n",
    "    xgb = XGBClassifier(**params)\n",
    "\n",
    "    # reg_cv_xgb = GridSearchCV(xgb, params, cv=folds, return_train_score=True)\n",
    "    # reg_cv_xgb.fit(X_train, y_train)\n",
    "    xgb.fit(_X_train, _y_train)\n",
    "\n",
    "    # print(reg_cv_xgb.best_params_)\n",
    "    # y_pred = reg_cv_xgb.predict(_X_val)\n",
    "    y_pred = xgb.predict(_X_test)\n",
    "\n",
    "    # y_ = np.concatenate([np.array([None for i in range(len(y_train))]) , y_pred])\n",
    "    # y_ = pd.DataFrame(y_, index=X.index)\n",
    "\n",
    "    # plt.figure(figsize=(16,5))\n",
    "    # plt.plot(y, label='original')\n",
    "    # plt.plot(y_, '--', label='predict')\n",
    "    # plt.legend()\n",
    "    # plt.show()\n",
    "\n",
    "    # plt.figure(figsize=(16,5))\n",
    "    # plt.plot(y[-50:], label='original')\n",
    "    # plt.plot(y_[-50:], '--', label='predict')\n",
    "    # plt.legend()\n",
    "    # plt.show()\n",
    "\n",
    "    # return np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    return 1 - accuracy_score(_y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "gHkOs8YPact6",
    "outputId": "20987326-851b-4238-8371-e791aa1a8040"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>y</th>\n",
       "      <th>sma5_close</th>\n",
       "      <th>sma20_close</th>\n",
       "      <th>rsi14_rsi</th>\n",
       "      <th>macd_macd</th>\n",
       "      <th>bband_+2a</th>\n",
       "      <th>bband_-2z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>107.684</td>\n",
       "      <td>107.742</td>\n",
       "      <td>107.642</td>\n",
       "      <td>107.702</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000245</td>\n",
       "      <td>0.999025</td>\n",
       "      <td>56.171987</td>\n",
       "      <td>0.055236</td>\n",
       "      <td>1.001992</td>\n",
       "      <td>0.996057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>107.702</td>\n",
       "      <td>107.845</td>\n",
       "      <td>107.659</td>\n",
       "      <td>107.790</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.998294</td>\n",
       "      <td>60.827529</td>\n",
       "      <td>0.060864</td>\n",
       "      <td>1.001360</td>\n",
       "      <td>0.995228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>107.791</td>\n",
       "      <td>107.822</td>\n",
       "      <td>107.758</td>\n",
       "      <td>107.791</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>6</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999451</td>\n",
       "      <td>0.998298</td>\n",
       "      <td>60.878384</td>\n",
       "      <td>0.064660</td>\n",
       "      <td>1.001390</td>\n",
       "      <td>0.995205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>107.791</td>\n",
       "      <td>107.830</td>\n",
       "      <td>107.757</td>\n",
       "      <td>107.780</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999716</td>\n",
       "      <td>0.998458</td>\n",
       "      <td>59.956304</td>\n",
       "      <td>0.066019</td>\n",
       "      <td>1.001625</td>\n",
       "      <td>0.995291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>107.780</td>\n",
       "      <td>107.820</td>\n",
       "      <td>107.731</td>\n",
       "      <td>107.732</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000251</td>\n",
       "      <td>0.999054</td>\n",
       "      <td>55.972369</td>\n",
       "      <td>0.062503</td>\n",
       "      <td>1.002129</td>\n",
       "      <td>0.995978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27602</th>\n",
       "      <td>108.873</td>\n",
       "      <td>108.873</td>\n",
       "      <td>108.837</td>\n",
       "      <td>108.843</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>12</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000068</td>\n",
       "      <td>1.000324</td>\n",
       "      <td>45.831825</td>\n",
       "      <td>-0.003790</td>\n",
       "      <td>1.000985</td>\n",
       "      <td>0.999664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27603</th>\n",
       "      <td>108.841</td>\n",
       "      <td>108.854</td>\n",
       "      <td>108.746</td>\n",
       "      <td>108.767</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000662</td>\n",
       "      <td>1.000999</td>\n",
       "      <td>38.045058</td>\n",
       "      <td>-0.011754</td>\n",
       "      <td>1.001764</td>\n",
       "      <td>1.000235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27604</th>\n",
       "      <td>108.768</td>\n",
       "      <td>108.774</td>\n",
       "      <td>108.666</td>\n",
       "      <td>108.698</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000970</td>\n",
       "      <td>1.001572</td>\n",
       "      <td>32.625462</td>\n",
       "      <td>-0.023364</td>\n",
       "      <td>1.002609</td>\n",
       "      <td>1.000536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27605</th>\n",
       "      <td>108.698</td>\n",
       "      <td>108.736</td>\n",
       "      <td>108.693</td>\n",
       "      <td>108.728</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000495</td>\n",
       "      <td>1.001242</td>\n",
       "      <td>36.838341</td>\n",
       "      <td>-0.029801</td>\n",
       "      <td>1.002421</td>\n",
       "      <td>1.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27606</th>\n",
       "      <td>108.728</td>\n",
       "      <td>108.728</td>\n",
       "      <td>108.715</td>\n",
       "      <td>108.721</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>13</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000280</td>\n",
       "      <td>1.001244</td>\n",
       "      <td>36.268474</td>\n",
       "      <td>-0.035062</td>\n",
       "      <td>1.002553</td>\n",
       "      <td>0.999935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27582 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          open     high      low    close  day  month  year  day_of_week  \\\n",
       "25     107.684  107.742  107.642  107.702    1      4  2020            2   \n",
       "26     107.702  107.845  107.659  107.790    1      4  2020            2   \n",
       "27     107.791  107.822  107.758  107.791    1      4  2020            2   \n",
       "28     107.791  107.830  107.757  107.780    1      4  2020            2   \n",
       "29     107.780  107.820  107.731  107.732    1      4  2020            2   \n",
       "...        ...      ...      ...      ...  ...    ...   ...          ...   \n",
       "27602  108.873  108.873  108.837  108.843   11      5  2021            1   \n",
       "27603  108.841  108.854  108.746  108.767   11      5  2021            1   \n",
       "27604  108.768  108.774  108.666  108.698   11      5  2021            1   \n",
       "27605  108.698  108.736  108.693  108.728   11      5  2021            1   \n",
       "27606  108.728  108.728  108.715  108.721   11      5  2021            1   \n",
       "\n",
       "       day_of_year  hour  minute  y  sma5_close  sma20_close  rsi14_rsi  \\\n",
       "25              92     6      15  1    1.000245     0.999025  56.171987   \n",
       "26              92     6      30  0    0.999438     0.998294  60.827529   \n",
       "27              92     6      45  0    0.999451     0.998298  60.878384   \n",
       "28              92     7       0  0    0.999716     0.998458  59.956304   \n",
       "29              92     7      15  0    1.000251     0.999054  55.972369   \n",
       "...            ...   ...     ... ..         ...          ...        ...   \n",
       "27602          131    12      45  2    1.000068     1.000324  45.831825   \n",
       "27603          131    13       0  2    1.000662     1.000999  38.045058   \n",
       "27604          131    13      15  0    1.000970     1.001572  32.625462   \n",
       "27605          131    13      30  0    1.000495     1.001242  36.838341   \n",
       "27606          131    13      45  0    1.000280     1.001244  36.268474   \n",
       "\n",
       "       macd_macd  bband_+2a  bband_-2z  \n",
       "25      0.055236   1.001992   0.996057  \n",
       "26      0.060864   1.001360   0.995228  \n",
       "27      0.064660   1.001390   0.995205  \n",
       "28      0.066019   1.001625   0.995291  \n",
       "29      0.062503   1.002129   0.995978  \n",
       "...          ...        ...        ...  \n",
       "27602  -0.003790   1.000985   0.999664  \n",
       "27603  -0.011754   1.001764   1.000235  \n",
       "27604  -0.023364   1.002609   1.000536  \n",
       "27605  -0.029801   1.002421   1.000064  \n",
       "27606  -0.035062   1.002553   0.999935  \n",
       "\n",
       "[27582 rows x 18 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2 = dataset.copy()\n",
    "\n",
    "# for i in range(1, 13):\n",
    "#     dataset2['shift%s'%i] = dataset2['close'].shift(i)\n",
    "\n",
    "# sma\n",
    "sma5 = ta.trend.SMAIndicator(dataset['close'], 5)\n",
    "sma20 = ta.trend.SMAIndicator(dataset['close'], 20)\n",
    "dataset2['sma5_close'] = sma5.sma_indicator() / dataset2['close']\n",
    "dataset2['sma20_close'] = sma20.sma_indicator() / dataset2['close']\n",
    "\n",
    "# rsi\n",
    "rsi14 = ta.momentum.RSIIndicator(dataset['close'], 14)\n",
    "dataset2['rsi14_rsi'] = rsi14.rsi()\n",
    "\n",
    "# macd\n",
    "macd = ta.trend.MACD(dataset2['close'])\n",
    "dataset2['macd_macd'] = macd.macd()\n",
    "\n",
    "# bollinger bands\n",
    "bband = ta.volatility.BollingerBands(dataset2['close'])\n",
    "dataset2['bband_+2a'] = bband.bollinger_hband() / dataset2['close']\n",
    "dataset2['bband_-2z'] = bband.bollinger_lband() / dataset2['close']\n",
    "\n",
    "dataset2 = dataset2.dropna()\n",
    "dataset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uwmhw4Vm8gjr",
    "outputId": "ed6b82f2-fdf1-4bf6-b7d4-cecf866c1b41"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X = dataset2.drop(['y', 'close', 'low', 'high', 'open'], axis=1)\n",
    "X = dataset2.drop(['y'], axis=1)\n",
    "y = dataset2['y']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# feature_importance_model = RandomForestRegressor(random_state=0)\n",
    "feature_importance_model = RandomForestClassifier(random_state=0)\n",
    "feature_importance_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "AR_MPgpy9BJl",
    "outputId": "2c982858-329c-4c9d-9ae3-d3dd28f1d1eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0, 'sma5_close'),\n",
       " Text(1, 0, 'bband_-2z'),\n",
       " Text(2, 0, 'bband_+2a'),\n",
       " Text(3, 0, 'sma20_close'),\n",
       " Text(4, 0, 'macd_macd'),\n",
       " Text(5, 0, 'rsi14_rsi'),\n",
       " Text(6, 0, 'hour'),\n",
       " Text(7, 0, 'high'),\n",
       " Text(8, 0, 'low'),\n",
       " Text(9, 0, 'close'),\n",
       " Text(10, 0, 'open'),\n",
       " Text(11, 0, 'day_of_year'),\n",
       " Text(12, 0, 'day'),\n",
       " Text(13, 0, 'minute'),\n",
       " Text(14, 0, 'day_of_week'),\n",
       " Text(15, 0, 'month'),\n",
       " Text(16, 0, 'year')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = pd.DataFrame({\"feature\":X.columns,\"importances\":feature_importance_model.feature_importances_})\n",
    "f = f.sort_values(by=\"importances\",ascending=False) #並び替え\n",
    "\n",
    "g = sns.barplot(x=\"feature\",y=\"importances\",data=f)\n",
    "g.set_xticklabels(f[\"feature\"],rotation=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ne094pXM7517",
    "outputId": "f39ca787-b53b-4390-acd4-cb93a2ddcae9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-12 19:43:24,411]\u001b[0m A new study created in memory with name: no-name-7eecb282-877a-4247-bd38-9681fc722761\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:43:28,188]\u001b[0m Trial 0 finished with value: 0.20643553138454562 and parameters: {'max_depth': 3, 'reg_alpha': 3, 'reg_lambda': 2, 'min_child_weight': 4, 'gamma': 2, 'learning_rate': 0.001434404691986216, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.52, 'colsample_bynode': 0.23, 'colsample_bylevel': 0.45000000000000007, 'subsample': 0.9}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:43:31,412]\u001b[0m Trial 1 finished with value: 0.20643553138454562 and parameters: {'max_depth': 2, 'reg_alpha': 3, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 4, 'learning_rate': 0.007355642827252657, 'eval_metric': 'rmse', 'objective': 'reg:tweedie', 'colsample_bytree': 0.62, 'colsample_bynode': 0.33, 'colsample_bylevel': 0.27, 'subsample': 0.7}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:43:37,678]\u001b[0m Trial 2 finished with value: 0.20643553138454562 and parameters: {'max_depth': 10, 'reg_alpha': 3, 'reg_lambda': 0, 'min_child_weight': 5, 'gamma': 1, 'learning_rate': 0.002332033097398532, 'eval_metric': 'rmse', 'objective': 'reg:tweedie', 'colsample_bytree': 0.42000000000000004, 'colsample_bynode': 0.27, 'colsample_bylevel': 0.78, 'subsample': 0.95}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:43:43,544]\u001b[0m Trial 3 finished with value: 0.20643553138454562 and parameters: {'max_depth': 25, 'reg_alpha': 3, 'reg_lambda': 5, 'min_child_weight': 2, 'gamma': 5, 'learning_rate': 5.262389987891959e-06, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.21000000000000002, 'colsample_bynode': 0.82, 'colsample_bylevel': 0.49, 'subsample': 0.75}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:43:49,776]\u001b[0m Trial 4 finished with value: 0.20643553138454562 and parameters: {'max_depth': 10, 'reg_alpha': 3, 'reg_lambda': 2, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.01565149503334692, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.23, 'colsample_bynode': 0.44000000000000006, 'colsample_bylevel': 0.5700000000000001, 'subsample': 0.6}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:44:08,027]\u001b[0m Trial 5 finished with value: 0.31815091774303195 and parameters: {'max_depth': 14, 'reg_alpha': 3, 'reg_lambda': 1, 'min_child_weight': 1, 'gamma': 0, 'learning_rate': 0.1621620992307834, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.84, 'colsample_bynode': 0.45999999999999996, 'colsample_bylevel': 0.72, 'subsample': 0.75}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:44:16,953]\u001b[0m Trial 6 finished with value: 0.24631769771130752 and parameters: {'max_depth': 11, 'reg_alpha': 0, 'reg_lambda': 4, 'min_child_weight': 4, 'gamma': 4, 'learning_rate': 0.11263334083179852, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.37, 'colsample_bynode': 0.18, 'colsample_bylevel': 0.26, 'subsample': 0.8}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:44:24,385]\u001b[0m Trial 7 finished with value: 0.20643553138454562 and parameters: {'max_depth': 6, 'reg_alpha': 3, 'reg_lambda': 5, 'min_child_weight': 4, 'gamma': 0, 'learning_rate': 2.9261271371688887e-08, 'eval_metric': 'rmse', 'objective': 'reg:tweedie', 'colsample_bytree': 0.84, 'colsample_bynode': 0.76, 'colsample_bylevel': 0.4, 'subsample': 0.65}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:44:49,495]\u001b[0m Trial 8 finished with value: 0.2084749603444369 and parameters: {'max_depth': 17, 'reg_alpha': 1, 'reg_lambda': 3, 'min_child_weight': 2, 'gamma': 4, 'learning_rate': 1.4094320547224349e-06, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.97, 'colsample_bynode': 0.42000000000000004, 'colsample_bylevel': 0.95, 'subsample': 0.8500000000000001}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-12 19:44:59,462]\u001b[0m Trial 9 finished with value: 0.20643553138454562 and parameters: {'max_depth': 13, 'reg_alpha': 3, 'reg_lambda': 0, 'min_child_weight': 3, 'gamma': 3, 'learning_rate': 3.6571940914992696e-08, 'eval_metric': 'rmse', 'objective': 'reg:tweedie', 'colsample_bytree': 0.45999999999999996, 'colsample_bynode': 0.42000000000000004, 'colsample_bylevel': 0.88, 'subsample': 0.65}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:45:01,921]\u001b[0m Trial 10 finished with value: 0.20643553138454562 and parameters: {'max_depth': 2, 'reg_alpha': 5, 'reg_lambda': 2, 'min_child_weight': 5, 'gamma': 2, 'learning_rate': 0.0001156101510868626, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.67, 'colsample_bynode': 0.1, 'colsample_bylevel': 0.11, 'subsample': 1.0}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:45:05,203]\u001b[0m Trial 11 finished with value: 0.20643553138454562 and parameters: {'max_depth': 2, 'reg_alpha': 5, 'reg_lambda': 3, 'min_child_weight': 0, 'gamma': 2, 'learning_rate': 0.0007410092883040116, 'eval_metric': 'rmse', 'objective': 'reg:tweedie', 'colsample_bytree': 0.63, 'colsample_bynode': 0.27, 'colsample_bylevel': 0.26, 'subsample': 0.9}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:45:09,638]\u001b[0m Trial 12 finished with value: 0.3927033763879447 and parameters: {'max_depth': 4, 'reg_alpha': 1, 'reg_lambda': 4, 'min_child_weight': 0, 'gamma': 5, 'learning_rate': 0.9378223290680874, 'eval_metric': 'rmse', 'objective': 'reg:tweedie', 'colsample_bytree': 0.5700000000000001, 'colsample_bynode': 0.6, 'colsample_bylevel': 0.29000000000000004, 'subsample': 0.5}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:45:14,492]\u001b[0m Trial 13 finished with value: 0.20643553138454562 and parameters: {'max_depth': 6, 'reg_alpha': 4, 'reg_lambda': 1, 'min_child_weight': 3, 'gamma': 4, 'learning_rate': 0.007574814485203446, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.74, 'colsample_bynode': 0.27, 'colsample_bylevel': 0.1, 'subsample': 0.8500000000000001}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:45:21,034]\u001b[0m Trial 14 finished with value: 0.20643553138454562 and parameters: {'max_depth': 22, 'reg_alpha': 2, 'reg_lambda': 2, 'min_child_weight': 1, 'gamma': 1, 'learning_rate': 0.00013076286958940876, 'eval_metric': 'rmse', 'objective': 'reg:tweedie', 'colsample_bytree': 0.51, 'colsample_bynode': 0.11, 'colsample_bylevel': 0.58, 'subsample': 0.55}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:45:25,964]\u001b[0m Trial 15 finished with value: 0.20643553138454562 and parameters: {'max_depth': 6, 'reg_alpha': 4, 'reg_lambda': 4, 'min_child_weight': 4, 'gamma': 3, 'learning_rate': 3.886506700642043e-06, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.33, 'colsample_bynode': 0.61, 'colsample_bylevel': 0.41000000000000003, 'subsample': 0.7}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:45:29,049]\u001b[0m Trial 16 finished with value: 0.20892816677996828 and parameters: {'max_depth': 3, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 3, 'gamma': 2, 'learning_rate': 0.046956143210990994, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.71, 'colsample_bynode': 0.98, 'colsample_bylevel': 0.19, 'subsample': 1.0}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:45:34,092]\u001b[0m Trial 17 finished with value: 0.20643553138454562 and parameters: {'max_depth': 8, 'reg_alpha': 4, 'reg_lambda': 1, 'min_child_weight': 2, 'gamma': 1, 'learning_rate': 0.0012532102138640548, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.11, 'colsample_bynode': 0.32, 'colsample_bylevel': 0.4, 'subsample': 0.9}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:45:39,110]\u001b[0m Trial 18 finished with value: 0.20643553138454562 and parameters: {'max_depth': 6, 'reg_alpha': 4, 'reg_lambda': 4, 'min_child_weight': 4, 'gamma': 3, 'learning_rate': 3.6734473175051047e-06, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.33, 'colsample_bynode': 0.63, 'colsample_bylevel': 0.43000000000000005, 'subsample': 0.8}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:45:44,383]\u001b[0m Trial 19 finished with value: 0.20643553138454562 and parameters: {'max_depth': 18, 'reg_alpha': 5, 'reg_lambda': 4, 'min_child_weight': 5, 'gamma': 2, 'learning_rate': 2.693081437465424e-07, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.27, 'colsample_bynode': 0.71, 'colsample_bylevel': 0.64, 'subsample': 0.7}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:45:49,482]\u001b[0m Trial 20 finished with value: 0.20643553138454562 and parameters: {'max_depth': 8, 'reg_alpha': 4, 'reg_lambda': 1, 'min_child_weight': 2, 'gamma': 1, 'learning_rate': 0.0004361318150698612, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.1, 'colsample_bynode': 0.2, 'colsample_bylevel': 0.49, 'subsample': 0.95}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:45:55,133]\u001b[0m Trial 21 finished with value: 0.20643553138454562 and parameters: {'max_depth': 8, 'reg_alpha': 4, 'reg_lambda': 1, 'min_child_weight': 4, 'gamma': 1, 'learning_rate': 1.9363935467242183e-05, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.18, 'colsample_bynode': 0.56, 'colsample_bylevel': 0.39, 'subsample': 0.8500000000000001}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:46:03,622]\u001b[0m Trial 22 finished with value: 0.20643553138454562 and parameters: {'max_depth': 20, 'reg_alpha': 5, 'reg_lambda': 4, 'min_child_weight': 5, 'gamma': 2, 'learning_rate': 2.532898206026608e-07, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.32, 'colsample_bynode': 0.73, 'colsample_bylevel': 0.66, 'subsample': 0.8}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:46:08,488]\u001b[0m Trial 23 finished with value: 0.20643553138454562 and parameters: {'max_depth': 17, 'reg_alpha': 5, 'reg_lambda': 2, 'min_child_weight': 5, 'gamma': 1, 'learning_rate': 0.00025033263082380224, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.1, 'colsample_bynode': 0.94, 'colsample_bylevel': 0.64, 'subsample': 0.95}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:46:17,419]\u001b[0m Trial 24 finished with value: 0.20643553138454562 and parameters: {'max_depth': 9, 'reg_alpha': 4, 'reg_lambda': 1, 'min_child_weight': 3, 'gamma': 0, 'learning_rate': 4.6591624527725814e-05, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.15000000000000002, 'colsample_bynode': 0.52, 'colsample_bylevel': 0.5, 'subsample': 0.9}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:46:30,823]\u001b[0m Trial 25 finished with value: 0.2071153410378428 and parameters: {'max_depth': 21, 'reg_alpha': 5, 'reg_lambda': 0, 'min_child_weight': 4, 'gamma': 2, 'learning_rate': 2.4782554792081806e-05, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.48, 'colsample_bynode': 0.89, 'colsample_bylevel': 0.7, 'subsample': 0.8}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:46:37,078]\u001b[0m Trial 26 finished with value: 0.20643553138454562 and parameters: {'max_depth': 13, 'reg_alpha': 2, 'reg_lambda': 1, 'min_child_weight': 2, 'gamma': 1, 'learning_rate': 0.0006872881204592413, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.1, 'colsample_bynode': 0.19, 'colsample_bylevel': 0.33999999999999997, 'subsample': 0.95}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:46:42,710]\u001b[0m Trial 27 finished with value: 0.20643553138454562 and parameters: {'max_depth': 16, 'reg_alpha': 4, 'reg_lambda': 2, 'min_child_weight': 3, 'gamma': 0, 'learning_rate': 3.2302608708957476e-05, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.16, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.51, 'subsample': 0.9}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-12 19:47:11,334]\u001b[0m Trial 28 finished with value: 0.30274189893496484 and parameters: {'max_depth': 15, 'reg_alpha': 5, 'reg_lambda': 2, 'min_child_weight': 5, 'gamma': 0, 'learning_rate': 0.0002596768165364894, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.96, 'colsample_bynode': 1.0, 'colsample_bylevel': 0.84, 'subsample': 1.0}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:47:18,784]\u001b[0m Trial 29 finished with value: 0.20643553138454562 and parameters: {'max_depth': 12, 'reg_alpha': 2, 'reg_lambda': 1, 'min_child_weight': 3, 'gamma': 0, 'learning_rate': 0.002682775416208327, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.25, 'colsample_bynode': 0.37, 'colsample_bylevel': 0.31, 'subsample': 0.95}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:47:26,927]\u001b[0m Trial 30 finished with value: 0.20643553138454562 and parameters: {'max_depth': 15, 'reg_alpha': 1, 'reg_lambda': 2, 'min_child_weight': 2, 'gamma': 1, 'learning_rate': 0.003236731932022162, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.15000000000000002, 'colsample_bynode': 0.18, 'colsample_bylevel': 0.33999999999999997, 'subsample': 0.9}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:47:33,726]\u001b[0m Trial 31 finished with value: 0.20643553138454562 and parameters: {'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 1, 'min_child_weight': 3, 'gamma': 0, 'learning_rate': 2.0850243016102442e-05, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.16, 'colsample_bynode': 0.47, 'colsample_bylevel': 0.49, 'subsample': 0.9}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:47:41,182]\u001b[0m Trial 32 finished with value: 0.20643553138454562 and parameters: {'max_depth': 11, 'reg_alpha': 2, 'reg_lambda': 0, 'min_child_weight': 3, 'gamma': 0, 'learning_rate': 0.0046284209418309945, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.28, 'colsample_bynode': 0.37, 'colsample_bylevel': 0.2, 'subsample': 0.95}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:47:49,741]\u001b[0m Trial 33 finished with value: 0.20643553138454562 and parameters: {'max_depth': 19, 'reg_alpha': 1, 'reg_lambda': 2, 'min_child_weight': 3, 'gamma': 0, 'learning_rate': 0.0022737329925339037, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.4, 'colsample_bynode': 0.33999999999999997, 'colsample_bylevel': 0.54, 'subsample': 0.8500000000000001}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:48:07,145]\u001b[0m Trial 34 finished with value: 0.20734194425560848 and parameters: {'max_depth': 23, 'reg_alpha': 0, 'reg_lambda': 0, 'min_child_weight': 2, 'gamma': 1, 'learning_rate': 0.018878628199417945, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.24000000000000002, 'colsample_bynode': 0.14, 'colsample_bylevel': 0.31, 'subsample': 0.9}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:48:15,563]\u001b[0m Trial 35 finished with value: 0.20643553138454562 and parameters: {'max_depth': 15, 'reg_alpha': 1, 'reg_lambda': 0, 'min_child_weight': 3, 'gamma': 1, 'learning_rate': 0.006679931607980562, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.28, 'colsample_bynode': 0.25, 'colsample_bylevel': 0.2, 'subsample': 1.0}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:48:24,927]\u001b[0m Trial 36 finished with value: 0.42012236573759343 and parameters: {'max_depth': 19, 'reg_alpha': 2, 'reg_lambda': 0, 'min_child_weight': 4, 'gamma': 0, 'learning_rate': 0.6078992210998935, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.44000000000000006, 'colsample_bynode': 0.35, 'colsample_bylevel': 0.58, 'subsample': 0.8500000000000001}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:48:36,135]\u001b[0m Trial 37 finished with value: 0.2087015635622026 and parameters: {'max_depth': 24, 'reg_alpha': 1, 'reg_lambda': 2, 'min_child_weight': 3, 'gamma': 0, 'learning_rate': 0.031473559948701664, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.38, 'colsample_bynode': 0.38, 'colsample_bylevel': 0.45000000000000007, 'subsample': 0.95}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:48:45,063]\u001b[0m Trial 38 finished with value: 0.2066621346023113 and parameters: {'max_depth': 19, 'reg_alpha': 1, 'reg_lambda': 0, 'min_child_weight': 4, 'gamma': 1, 'learning_rate': 0.007079298516943196, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.54, 'colsample_bynode': 0.31, 'colsample_bylevel': 0.2, 'subsample': 1.0}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:48:53,912]\u001b[0m Trial 39 finished with value: 0.34421028778608653 and parameters: {'max_depth': 12, 'reg_alpha': 0, 'reg_lambda': 0, 'min_child_weight': 3, 'gamma': 0, 'learning_rate': 0.16964336977743286, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.4, 'colsample_bynode': 0.25, 'colsample_bylevel': 0.16, 'subsample': 1.0}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:49:02,051]\u001b[0m Trial 40 finished with value: 0.20643553138454562 and parameters: {'max_depth': 14, 'reg_alpha': 1, 'reg_lambda': 3, 'min_child_weight': 4, 'gamma': 2, 'learning_rate': 0.0064697723395288065, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.31, 'colsample_bynode': 0.4, 'colsample_bylevel': 0.22, 'subsample': 0.75}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:49:09,353]\u001b[0m Trial 41 finished with value: 0.20643553138454562 and parameters: {'max_depth': 16, 'reg_alpha': 3, 'reg_lambda': 0, 'min_child_weight': 3, 'gamma': 0, 'learning_rate': 0.0013797167673816099, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.2, 'colsample_bynode': 0.23, 'colsample_bylevel': 0.15000000000000002, 'subsample': 0.8500000000000001}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:49:20,026]\u001b[0m Trial 42 finished with value: 0.20643553138454562 and parameters: {'max_depth': 20, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 5, 'gamma': 2, 'learning_rate': 3.382366100637691e-07, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.32, 'colsample_bynode': 0.73, 'colsample_bylevel': 0.64, 'subsample': 0.75}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:49:27,229]\u001b[0m Trial 43 finished with value: 0.20643553138454562 and parameters: {'max_depth': 17, 'reg_alpha': 3, 'reg_lambda': 3, 'min_child_weight': 5, 'gamma': 2, 'learning_rate': 0.0005351136228593347, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.2, 'colsample_bynode': 0.9, 'colsample_bylevel': 0.74, 'subsample': 0.8}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:49:35,946]\u001b[0m Trial 44 finished with value: 0.20643553138454562 and parameters: {'max_depth': 21, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 5, 'gamma': 2, 'learning_rate': 1.1063817668560488e-08, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.1, 'colsample_bynode': 0.74, 'colsample_bylevel': 0.65, 'subsample': 0.75}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:49:44,142]\u001b[0m Trial 45 finished with value: 0.20643553138454562 and parameters: {'max_depth': 9, 'reg_alpha': 3, 'reg_lambda': 3, 'min_child_weight': 5, 'gamma': 3, 'learning_rate': 6.853043074353319e-05, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.18, 'colsample_bynode': 0.88, 'colsample_bylevel': 0.76, 'subsample': 0.8}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:49:52,193]\u001b[0m Trial 46 finished with value: 0.20643553138454562 and parameters: {'max_depth': 4, 'reg_alpha': 4, 'reg_lambda': 1, 'min_child_weight': 4, 'gamma': 1, 'learning_rate': 1.3868890401337064e-08, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.12000000000000001, 'colsample_bynode': 0.56, 'colsample_bylevel': 0.61, 'subsample': 0.65}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-12 19:50:09,414]\u001b[0m Trial 47 finished with value: 0.2071153410378428 and parameters: {'max_depth': 9, 'reg_alpha': 3, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 5.010161975135487e-05, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.62, 'colsample_bynode': 0.8099999999999999, 'colsample_bylevel': 0.79, 'subsample': 0.8}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:50:12,871]\u001b[0m Trial 48 finished with value: 0.20643553138454562 and parameters: {'max_depth': 2, 'reg_alpha': 4, 'reg_lambda': 1, 'min_child_weight': 2, 'gamma': 1, 'learning_rate': 8.417168658925175e-08, 'eval_metric': 'rmse', 'objective': 'reg:gamma', 'colsample_bytree': 0.13, 'colsample_bynode': 0.67, 'colsample_bylevel': 0.36, 'subsample': 0.65}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:50:40,898]\u001b[0m Trial 49 finished with value: 0.20915476999773397 and parameters: {'max_depth': 18, 'reg_alpha': 5, 'reg_lambda': 2, 'min_child_weight': 5, 'gamma': 2, 'learning_rate': 0.00027138501989209136, 'eval_metric': 'rmse', 'objective': 'reg:tweedie', 'colsample_bytree': 0.8099999999999999, 'colsample_bynode': 0.96, 'colsample_bylevel': 0.69, 'subsample': 0.95}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:50:44,813]\u001b[0m Trial 50 finished with value: 0.20643553138454562 and parameters: {'max_depth': 2, 'reg_alpha': 3, 'reg_lambda': 2, 'min_child_weight': 1, 'gamma': 1, 'learning_rate': 8.056967804156877e-06, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.91, 'colsample_bynode': 0.6799999999999999, 'colsample_bylevel': 0.35, 'subsample': 0.5}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:50:52,701]\u001b[0m Trial 51 finished with value: 0.20643553138454562 and parameters: {'max_depth': 13, 'reg_alpha': 2, 'reg_lambda': 1, 'min_child_weight': 2, 'gamma': 0, 'learning_rate': 0.00015479696665139317, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.22, 'colsample_bynode': 0.53, 'colsample_bylevel': 0.52, 'subsample': 0.95}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:51:08,403]\u001b[0m Trial 52 finished with value: 0.21074099252209377 and parameters: {'max_depth': 12, 'reg_alpha': 3, 'reg_lambda': 2, 'min_child_weight': 1, 'gamma': 0, 'learning_rate': 1.4269457573444088e-06, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.99, 'colsample_bynode': 0.47, 'colsample_bylevel': 0.45999999999999996, 'subsample': 0.9}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:51:17,003]\u001b[0m Trial 53 finished with value: 0.20643553138454562 and parameters: {'max_depth': 14, 'reg_alpha': 2, 'reg_lambda': 1, 'min_child_weight': 2, 'gamma': 0, 'learning_rate': 0.002513651375758827, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.24000000000000002, 'colsample_bynode': 0.51, 'colsample_bylevel': 0.54, 'subsample': 0.9}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:51:24,105]\u001b[0m Trial 54 finished with value: 0.20643553138454562 and parameters: {'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 2, 'min_child_weight': 3, 'gamma': 0, 'learning_rate': 5.664617861003537e-06, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.15000000000000002, 'colsample_bynode': 0.48, 'colsample_bylevel': 0.49, 'subsample': 0.9}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:51:31,546]\u001b[0m Trial 55 finished with value: 0.20643553138454562 and parameters: {'max_depth': 11, 'reg_alpha': 2, 'reg_lambda': 1, 'min_child_weight': 2, 'gamma': 1, 'learning_rate': 0.0029582597779845006, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.26, 'colsample_bynode': 0.16, 'colsample_bylevel': 0.35, 'subsample': 0.95}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:51:38,694]\u001b[0m Trial 56 finished with value: 0.20643553138454562 and parameters: {'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 1, 'min_child_weight': 2, 'gamma': 1, 'learning_rate': 7.79757654472118e-06, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.15000000000000002, 'colsample_bynode': 0.47, 'colsample_bylevel': 0.30000000000000004, 'subsample': 0.9}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:51:48,939]\u001b[0m Trial 57 finished with value: 0.2293224563788806 and parameters: {'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 2, 'min_child_weight': 3, 'gamma': 0, 'learning_rate': 0.06430287372329488, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.36, 'colsample_bynode': 0.13, 'colsample_bylevel': 0.38, 'subsample': 0.95}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:51:55,079]\u001b[0m Trial 58 finished with value: 0.20643553138454562 and parameters: {'max_depth': 12, 'reg_alpha': 4, 'reg_lambda': 1, 'min_child_weight': 2, 'gamma': 1, 'learning_rate': 0.0010448398000648571, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.17, 'colsample_bynode': 0.44000000000000006, 'colsample_bylevel': 0.30000000000000004, 'subsample': 0.9}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n",
      "D:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2021-05-12 19:52:04,183]\u001b[0m Trial 59 finished with value: 0.20643553138454562 and parameters: {'max_depth': 18, 'reg_alpha': 1, 'reg_lambda': 2, 'min_child_weight': 3, 'gamma': 0, 'learning_rate': 1.7887736607691547e-05, 'eval_metric': 'rmse', 'objective': 'reg:linear', 'colsample_bytree': 0.47, 'colsample_bynode': 0.33999999999999997, 'colsample_bylevel': 0.55, 'subsample': 0.8500000000000001}. Best is trial 0 with value: 0.20643553138454562.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "X = dataset2.drop(['y'], axis=1)\n",
    "y = dataset2['y']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# folds = KFold(n_splits = 5, shuffle = True)\n",
    "# folds = TimeSeriesSplit(n_splits = 8)\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_fSMBULEZGvY",
    "outputId": "eb6a41a0-6087-4b22-8a67-642146b1a0ce"
   },
   "outputs": [],
   "source": [
    "print(study.best_params)\n",
    "print(study.best_value)\n",
    "print(study.best_trial)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y0cjWCoAZHaK"
   },
   "outputs": [],
   "source": [
    "xgb_ = XGBClassifier(**study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zBGmfA0v32NA",
    "outputId": "7e8571e3-bd06-4d66-f287-3a97fa5169ea"
   },
   "outputs": [],
   "source": [
    "xgb_.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22E5Ojxf6XA-",
    "outputId": "de2569e2-83b6-4a1f-88a9-a216d1e93c7e"
   },
   "outputs": [],
   "source": [
    "y_pred = xgb_.predict(X_val)\n",
    "accuracy_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "FcDmbeXq7GaS",
    "outputId": "a219b75a-4fe2-4e05-e860-3ad7389196b2"
   },
   "outputs": [],
   "source": [
    "verify = X_val.copy()\n",
    "verify['y_pred'] = y_pred\n",
    "verify['y'] = y_val\n",
    "verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "vHSBnWUFAmiT",
    "outputId": "a954975d-4d8a-4599-c26a-d4847a7e3d47"
   },
   "outputs": [],
   "source": [
    "verify[verify['y_pred'] != verify['y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n__Cj1n2A8XI",
    "outputId": "2b33a51a-de8d-467d-d8d1-16bbbfffea3f"
   },
   "outputs": [],
   "source": [
    "np.unique(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iA06t_p_BbAh",
    "outputId": "c48fbf79-34f3-4288-90d6-d204ee26f66a"
   },
   "outputs": [],
   "source": [
    "verify['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to JSON\n",
    "xgb_.save_model(\"model_v2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "20210509 - optuna",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
